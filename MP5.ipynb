{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment we will implement the Deep Q-Learning algorithm with Experience Replay as described in breakthrough paper __\"Playing Atari with Deep Reinforcement Learning\"__. We will train an agent to play the famous game of __Breakout__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gym\n",
    "import torch\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from utils import *\n",
    "from agent import *\n",
    "from model import *\n",
    "from config import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we initialise our game of __Breakout__ and you can see how the environment looks like. For further documentation of the of the environment refer to https://gym.openai.com/envs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrewcaldwell/.local/lib/python3.5/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "# env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_lives = find_max_lifes(env)\n",
    "state_size = env.observation_space.shape\n",
    "action_size = 3\n",
    "rewards, episodes = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DQN Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a DQN Agent. This agent is defined in the __agent.py__. The corresponding neural network is defined in the __model.py__. \n",
    "\n",
    "__Evaluation Reward__ : The average reward received in the past 100 episodes/games.\n",
    "\n",
    "__Frame__ : Number of frames processed in total.\n",
    "\n",
    "__Memory Size__ : The current size of the replay memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(action_size)\n",
    "evaluation_reward = deque(maxlen=evaluation_reward_length)\n",
    "frame = 0\n",
    "memory_size = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0   score: 0.0   memory length: 133   epsilon: 1.0    steps: 133     evaluation reward: 0.0 frames: 133\n",
      "episode: 1   score: 0.0   memory length: 267   epsilon: 1.0    steps: 134     evaluation reward: 0.0 frames: 267\n",
      "episode: 2   score: 3.0   memory length: 514   epsilon: 1.0    steps: 247     evaluation reward: 1.0 frames: 514\n",
      "episode: 3   score: 2.0   memory length: 718   epsilon: 1.0    steps: 204     evaluation reward: 1.25 frames: 718\n",
      "episode: 4   score: 1.0   memory length: 878   epsilon: 1.0    steps: 160     evaluation reward: 1.2 frames: 878\n",
      "episode: 5   score: 1.0   memory length: 1038   epsilon: 0.9980694999999986    steps: 160     evaluation reward: 1.1666666666666667 frames: 1038\n",
      "episode: 6   score: 0.0   memory length: 1176   epsilon: 0.9912384999999937    steps: 138     evaluation reward: 1.0 frames: 1176\n",
      "episode: 7   score: 2.0   memory length: 1380   epsilon: 0.9811404999999864    steps: 204     evaluation reward: 1.125 frames: 1380\n",
      "episode: 8   score: 1.0   memory length: 1547   epsilon: 0.9728739999999805    steps: 167     evaluation reward: 1.1111111111111112 frames: 1547\n",
      "episode: 9   score: 0.0   memory length: 1678   epsilon: 0.9663894999999758    steps: 131     evaluation reward: 1.0 frames: 1678\n",
      "episode: 10   score: 0.0   memory length: 1808   epsilon: 0.9599544999999712    steps: 130     evaluation reward: 0.9090909090909091 frames: 1808\n",
      "episode: 11   score: 0.0   memory length: 1943   epsilon: 0.9532719999999664    steps: 135     evaluation reward: 0.8333333333333334 frames: 1943\n",
      "episode: 12   score: 1.0   memory length: 2120   epsilon: 0.9445104999999601    steps: 177     evaluation reward: 0.8461538461538461 frames: 2120\n",
      "episode: 13   score: 2.0   memory length: 2333   epsilon: 0.9339669999999525    steps: 213     evaluation reward: 0.9285714285714286 frames: 2333\n",
      "episode: 14   score: 1.0   memory length: 2509   epsilon: 0.9252549999999462    steps: 176     evaluation reward: 0.9333333333333333 frames: 2509\n",
      "episode: 15   score: 0.0   memory length: 2635   epsilon: 0.9190179999999417    steps: 126     evaluation reward: 0.875 frames: 2635\n",
      "episode: 16   score: 0.0   memory length: 2760   epsilon: 0.9128304999999373    steps: 125     evaluation reward: 0.8235294117647058 frames: 2760\n",
      "episode: 17   score: 0.0   memory length: 2896   epsilon: 0.9060984999999324    steps: 136     evaluation reward: 0.7777777777777778 frames: 2896\n",
      "episode: 18   score: 3.0   memory length: 3165   epsilon: 0.8927829999999228    steps: 269     evaluation reward: 0.8947368421052632 frames: 3165\n",
      "episode: 19   score: 3.0   memory length: 3419   epsilon: 0.8802099999999138    steps: 254     evaluation reward: 1.0 frames: 3419\n",
      "episode: 20   score: 1.0   memory length: 3595   epsilon: 0.8714979999999075    steps: 176     evaluation reward: 1.0 frames: 3595\n",
      "episode: 21   score: 1.0   memory length: 3769   epsilon: 0.8628849999999013    steps: 174     evaluation reward: 1.0 frames: 3769\n",
      "episode: 22   score: 1.0   memory length: 3951   epsilon: 0.8538759999998948    steps: 182     evaluation reward: 1.0 frames: 3951\n",
      "episode: 23   score: 0.0   memory length: 4077   epsilon: 0.8476389999998903    steps: 126     evaluation reward: 0.9583333333333334 frames: 4077\n",
      "episode: 24   score: 3.0   memory length: 4311   epsilon: 0.836055999999882    steps: 234     evaluation reward: 1.04 frames: 4311\n",
      "episode: 25   score: 1.0   memory length: 4485   epsilon: 0.8274429999998758    steps: 174     evaluation reward: 1.0384615384615385 frames: 4485\n",
      "episode: 26   score: 1.0   memory length: 4638   epsilon: 0.8198694999998704    steps: 153     evaluation reward: 1.037037037037037 frames: 4638\n",
      "episode: 27   score: 1.0   memory length: 4818   epsilon: 0.8109594999998639    steps: 180     evaluation reward: 1.0357142857142858 frames: 4818\n",
      "episode: 28   score: 4.0   memory length: 5086   epsilon: 0.7976934999998544    steps: 268     evaluation reward: 1.1379310344827587 frames: 5086\n",
      "episode: 29   score: 2.0   memory length: 5292   epsilon: 0.787496499999847    steps: 206     evaluation reward: 1.1666666666666667 frames: 5292\n",
      "episode: 30   score: 1.0   memory length: 5467   epsilon: 0.7788339999998408    steps: 175     evaluation reward: 1.1612903225806452 frames: 5467\n",
      "episode: 31   score: 2.0   memory length: 5689   epsilon: 0.7678449999998329    steps: 222     evaluation reward: 1.1875 frames: 5689\n",
      "episode: 32   score: 1.0   memory length: 5861   epsilon: 0.7593309999998268    steps: 172     evaluation reward: 1.1818181818181819 frames: 5861\n",
      "episode: 33   score: 6.0   memory length: 6205   epsilon: 0.7423029999998145    steps: 344     evaluation reward: 1.3235294117647058 frames: 6205\n",
      "episode: 34   score: 2.0   memory length: 6409   epsilon: 0.7322049999998073    steps: 204     evaluation reward: 1.3428571428571427 frames: 6409\n",
      "episode: 35   score: 2.0   memory length: 6618   epsilon: 0.7218594999997998    steps: 209     evaluation reward: 1.3611111111111112 frames: 6618\n",
      "episode: 36   score: 0.0   memory length: 6751   epsilon: 0.7152759999997951    steps: 133     evaluation reward: 1.3243243243243243 frames: 6751\n",
      "episode: 37   score: 0.0   memory length: 6877   epsilon: 0.7090389999997906    steps: 126     evaluation reward: 1.2894736842105263 frames: 6877\n",
      "episode: 38   score: 3.0   memory length: 7125   epsilon: 0.6967629999997818    steps: 248     evaluation reward: 1.3333333333333333 frames: 7125\n",
      "episode: 39   score: 1.0   memory length: 7283   epsilon: 0.6889419999997761    steps: 158     evaluation reward: 1.325 frames: 7283\n",
      "episode: 40   score: 2.0   memory length: 7491   epsilon: 0.6786459999997687    steps: 208     evaluation reward: 1.3414634146341464 frames: 7491\n",
      "episode: 41   score: 1.0   memory length: 7659   epsilon: 0.6703299999997627    steps: 168     evaluation reward: 1.3333333333333333 frames: 7659\n",
      "episode: 42   score: 0.0   memory length: 7794   epsilon: 0.6636474999997579    steps: 135     evaluation reward: 1.302325581395349 frames: 7794\n",
      "episode: 43   score: 0.0   memory length: 7926   epsilon: 0.6571134999997532    steps: 132     evaluation reward: 1.2727272727272727 frames: 7926\n",
      "episode: 44   score: 1.0   memory length: 8083   epsilon: 0.6493419999997476    steps: 157     evaluation reward: 1.2666666666666666 frames: 8083\n",
      "episode: 45   score: 4.0   memory length: 8364   epsilon: 0.6354324999997376    steps: 281     evaluation reward: 1.326086956521739 frames: 8364\n",
      "episode: 46   score: 0.0   memory length: 8497   epsilon: 0.6288489999997329    steps: 133     evaluation reward: 1.297872340425532 frames: 8497\n",
      "episode: 47   score: 0.0   memory length: 8621   epsilon: 0.6227109999997285    steps: 124     evaluation reward: 1.2708333333333333 frames: 8621\n",
      "episode: 48   score: 1.0   memory length: 8776   epsilon: 0.6150384999997229    steps: 155     evaluation reward: 1.2653061224489797 frames: 8776\n",
      "episode: 49   score: 2.0   memory length: 8988   epsilon: 0.6045444999997154    steps: 212     evaluation reward: 1.28 frames: 8988\n",
      "episode: 50   score: 3.0   memory length: 9225   epsilon: 0.5928129999997069    steps: 237     evaluation reward: 1.3137254901960784 frames: 9225\n",
      "episode: 51   score: 2.0   memory length: 9437   epsilon: 0.5823189999996994    steps: 212     evaluation reward: 1.3269230769230769 frames: 9437\n",
      "episode: 52   score: 0.0   memory length: 9570   epsilon: 0.5757354999996946    steps: 133     evaluation reward: 1.3018867924528301 frames: 9570\n",
      "episode: 53   score: 0.0   memory length: 9699   epsilon: 0.56934999999969    steps: 129     evaluation reward: 1.2777777777777777 frames: 9699\n",
      "episode: 54   score: 0.0   memory length: 9827   epsilon: 0.5630139999996855    steps: 128     evaluation reward: 1.2545454545454546 frames: 9827\n",
      "episode: 55   score: 1.0   memory length: 9993   epsilon: 0.5547969999996796    steps: 166     evaluation reward: 1.25 frames: 9993\n",
      "episode: 56   score: 2.0   memory length: 10185   epsilon: 0.5452929999996727    steps: 192     evaluation reward: 1.263157894736842 frames: 10185\n",
      "episode: 57   score: 0.0   memory length: 10319   epsilon: 0.538659999999668    steps: 134     evaluation reward: 1.2413793103448276 frames: 10319\n",
      "episode: 58   score: 2.0   memory length: 10547   epsilon: 0.5273739999996598    steps: 228     evaluation reward: 1.2542372881355932 frames: 10547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 59   score: 0.0   memory length: 10673   epsilon: 0.5211369999996553    steps: 126     evaluation reward: 1.2333333333333334 frames: 10673\n",
      "episode: 60   score: 2.0   memory length: 10906   epsilon: 0.509603499999647    steps: 233     evaluation reward: 1.2459016393442623 frames: 10906\n",
      "episode: 61   score: 0.0   memory length: 11050   epsilon: 0.5024754999996419    steps: 144     evaluation reward: 1.2258064516129032 frames: 11050\n",
      "episode: 62   score: 3.0   memory length: 11298   epsilon: 0.4901994999996441    steps: 248     evaluation reward: 1.253968253968254 frames: 11298\n",
      "episode: 63   score: 2.0   memory length: 11499   epsilon: 0.48024999999964807    steps: 201     evaluation reward: 1.265625 frames: 11499\n",
      "episode: 64   score: 0.0   memory length: 11641   epsilon: 0.4732209999996509    steps: 142     evaluation reward: 1.2461538461538462 frames: 11641\n",
      "episode: 65   score: 2.0   memory length: 11851   epsilon: 0.46282599999965507    steps: 210     evaluation reward: 1.2575757575757576 frames: 11851\n",
      "episode: 66   score: 3.0   memory length: 12126   epsilon: 0.44921349999966054    steps: 275     evaluation reward: 1.2835820895522387 frames: 12126\n",
      "episode: 67   score: 4.0   memory length: 12406   epsilon: 0.4353534999996661    steps: 280     evaluation reward: 1.3235294117647058 frames: 12406\n",
      "episode: 68   score: 1.0   memory length: 12585   epsilon: 0.42649299999966966    steps: 179     evaluation reward: 1.318840579710145 frames: 12585\n",
      "episode: 69   score: 0.0   memory length: 12732   epsilon: 0.4192164999996726    steps: 147     evaluation reward: 1.3 frames: 12732\n",
      "episode: 70   score: 0.0   memory length: 12870   epsilon: 0.41238549999967533    steps: 138     evaluation reward: 1.2816901408450705 frames: 12870\n",
      "episode: 71   score: 0.0   memory length: 13014   epsilon: 0.4052574999996782    steps: 144     evaluation reward: 1.2638888888888888 frames: 13014\n",
      "episode: 72   score: 2.0   memory length: 13238   epsilon: 0.39416949999968265    steps: 224     evaluation reward: 1.273972602739726 frames: 13238\n",
      "episode: 73   score: 2.0   memory length: 13465   epsilon: 0.38293299999968716    steps: 227     evaluation reward: 1.2837837837837838 frames: 13465\n",
      "episode: 74   score: 3.0   memory length: 13692   epsilon: 0.3716964999996917    steps: 227     evaluation reward: 1.3066666666666666 frames: 13692\n",
      "episode: 75   score: 2.0   memory length: 13896   epsilon: 0.36159849999969573    steps: 204     evaluation reward: 1.3157894736842106 frames: 13896\n",
      "episode: 76   score: 2.0   memory length: 14101   epsilon: 0.3514509999996998    steps: 205     evaluation reward: 1.3246753246753247 frames: 14101\n",
      "episode: 77   score: 5.0   memory length: 14447   epsilon: 0.3343239999997067    steps: 346     evaluation reward: 1.3717948717948718 frames: 14447\n",
      "episode: 78   score: 1.0   memory length: 14632   epsilon: 0.32516649999971037    steps: 185     evaluation reward: 1.3670886075949367 frames: 14632\n",
      "episode: 79   score: 1.0   memory length: 14808   epsilon: 0.31645449999971387    steps: 176     evaluation reward: 1.3625 frames: 14808\n",
      "episode: 80   score: 0.0   memory length: 14992   epsilon: 0.3073464999997175    steps: 184     evaluation reward: 1.345679012345679 frames: 14992\n",
      "episode: 81   score: 1.0   memory length: 15183   epsilon: 0.2978919999997213    steps: 191     evaluation reward: 1.3414634146341464 frames: 15183\n",
      "episode: 82   score: 3.0   memory length: 15470   epsilon: 0.28368549999972703    steps: 287     evaluation reward: 1.3614457831325302 frames: 15470\n",
      "episode: 83   score: 11.0   memory length: 15780   epsilon: 0.2683404999997332    steps: 310     evaluation reward: 1.4761904761904763 frames: 15780\n",
      "episode: 84   score: 2.0   memory length: 15994   epsilon: 0.25774749999973745    steps: 214     evaluation reward: 1.4823529411764707 frames: 15994\n",
      "episode: 85   score: 2.0   memory length: 16184   epsilon: 0.24834249999974028    steps: 190     evaluation reward: 1.4883720930232558 frames: 16184\n",
      "episode: 86   score: 3.0   memory length: 16402   epsilon: 0.23755149999973857    steps: 218     evaluation reward: 1.5057471264367817 frames: 16402\n",
      "episode: 87   score: 1.0   memory length: 16557   epsilon: 0.22987899999973735    steps: 155     evaluation reward: 1.5 frames: 16557\n",
      "episode: 88   score: 1.0   memory length: 16710   epsilon: 0.22230549999973614    steps: 153     evaluation reward: 1.4943820224719102 frames: 16710\n",
      "episode: 89   score: 0.0   memory length: 16844   epsilon: 0.2156724999997351    steps: 134     evaluation reward: 1.4777777777777779 frames: 16844\n",
      "episode: 90   score: 4.0   memory length: 17148   epsilon: 0.2006244999997327    steps: 304     evaluation reward: 1.5054945054945055 frames: 17148\n",
      "episode: 91   score: 1.0   memory length: 17316   epsilon: 0.19230849999973137    steps: 168     evaluation reward: 1.5 frames: 17316\n",
      "episode: 92   score: 3.0   memory length: 17596   epsilon: 0.17844849999972917    steps: 280     evaluation reward: 1.5161290322580645 frames: 17596\n",
      "episode: 93   score: 3.0   memory length: 17875   epsilon: 0.16463799999972697    steps: 279     evaluation reward: 1.5319148936170213 frames: 17875\n",
      "episode: 94   score: 2.0   memory length: 18079   epsilon: 0.15453999999972537    steps: 204     evaluation reward: 1.5368421052631578 frames: 18079\n",
      "episode: 95   score: 2.0   memory length: 18283   epsilon: 0.14444199999972376    steps: 204     evaluation reward: 1.5416666666666667 frames: 18283\n",
      "episode: 96   score: 2.0   memory length: 18500   epsilon: 0.13370049999972206    steps: 217     evaluation reward: 1.5463917525773196 frames: 18500\n",
      "episode: 97   score: 2.0   memory length: 18712   epsilon: 0.1232064999997209    steps: 212     evaluation reward: 1.5510204081632653 frames: 18712\n",
      "episode: 98   score: 1.0   memory length: 18902   epsilon: 0.11380149999972204    steps: 190     evaluation reward: 1.5454545454545454 frames: 18902\n",
      "episode: 99   score: 1.0   memory length: 19130   epsilon: 0.10251549999972341    steps: 228     evaluation reward: 1.54 frames: 19130\n",
      "episode: 100   score: 3.0   memory length: 19383   epsilon: 0.08999199999972493    steps: 253     evaluation reward: 1.57 frames: 19383\n",
      "episode: 101   score: 1.0   memory length: 19601   epsilon: 0.07920099999972624    steps: 218     evaluation reward: 1.58 frames: 19601\n",
      "episode: 102   score: 1.0   memory length: 19867   epsilon: 0.06603399999972784    steps: 266     evaluation reward: 1.56 frames: 19867\n",
      "episode: 103   score: 4.0   memory length: 20286   epsilon: 0.04529349999972794    steps: 419     evaluation reward: 1.58 frames: 20286\n",
      "episode: 104   score: 1.0   memory length: 20496   epsilon: 0.034898499999727745    steps: 210     evaluation reward: 1.58 frames: 20496\n",
      "episode: 105   score: 7.0   memory length: 22064   epsilon: 0.009999999999727473    steps: 1568     evaluation reward: 1.64 frames: 22064\n",
      "episode: 106   score: 5.0   memory length: 22633   epsilon: 0.009999999999727473    steps: 569     evaluation reward: 1.69 frames: 22633\n",
      "episode: 107   score: 4.0   memory length: 23465   epsilon: 0.009999999999727473    steps: 832     evaluation reward: 1.71 frames: 23465\n",
      "episode: 108   score: 3.0   memory length: 23809   epsilon: 0.009999999999727473    steps: 344     evaluation reward: 1.73 frames: 23809\n",
      "episode: 109   score: 2.0   memory length: 23996   epsilon: 0.009999999999727473    steps: 187     evaluation reward: 1.75 frames: 23996\n",
      "episode: 110   score: 5.0   memory length: 24405   epsilon: 0.009999999999727473    steps: 409     evaluation reward: 1.8 frames: 24405\n",
      "episode: 111   score: 2.0   memory length: 25052   epsilon: 0.009999999999727473    steps: 647     evaluation reward: 1.82 frames: 25052\n",
      "episode: 112   score: 4.0   memory length: 25433   epsilon: 0.009999999999727473    steps: 381     evaluation reward: 1.85 frames: 25433\n",
      "episode: 113   score: 3.0   memory length: 25651   epsilon: 0.009999999999727473    steps: 218     evaluation reward: 1.86 frames: 25651\n",
      "episode: 114   score: 7.0   memory length: 26129   epsilon: 0.009999999999727473    steps: 478     evaluation reward: 1.92 frames: 26129\n",
      "episode: 115   score: 2.0   memory length: 26420   epsilon: 0.009999999999727473    steps: 291     evaluation reward: 1.94 frames: 26420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 116   score: 10.0   memory length: 26906   epsilon: 0.009999999999727473    steps: 486     evaluation reward: 2.04 frames: 26906\n",
      "episode: 117   score: 2.0   memory length: 27187   epsilon: 0.009999999999727473    steps: 281     evaluation reward: 2.06 frames: 27187\n",
      "episode: 118   score: 3.0   memory length: 28037   epsilon: 0.009999999999727473    steps: 850     evaluation reward: 2.06 frames: 28037\n",
      "episode: 119   score: 3.0   memory length: 28287   epsilon: 0.009999999999727473    steps: 250     evaluation reward: 2.06 frames: 28287\n",
      "episode: 120   score: 7.0   memory length: 28662   epsilon: 0.009999999999727473    steps: 375     evaluation reward: 2.12 frames: 28662\n",
      "episode: 121   score: 9.0   memory length: 29116   epsilon: 0.009999999999727473    steps: 454     evaluation reward: 2.2 frames: 29116\n",
      "episode: 122   score: 4.0   memory length: 29436   epsilon: 0.009999999999727473    steps: 320     evaluation reward: 2.23 frames: 29436\n",
      "episode: 123   score: 7.0   memory length: 29856   epsilon: 0.009999999999727473    steps: 420     evaluation reward: 2.3 frames: 29856\n",
      "episode: 124   score: 8.0   memory length: 30484   epsilon: 0.009999999999727473    steps: 628     evaluation reward: 2.35 frames: 30484\n",
      "episode: 125   score: 8.0   memory length: 31226   epsilon: 0.009999999999727473    steps: 742     evaluation reward: 2.42 frames: 31226\n",
      "episode: 126   score: 7.0   memory length: 32174   epsilon: 0.009999999999727473    steps: 948     evaluation reward: 2.48 frames: 32174\n",
      "episode: 127   score: 7.0   memory length: 32458   epsilon: 0.009999999999727473    steps: 284     evaluation reward: 2.54 frames: 32458\n",
      "episode: 128   score: 7.0   memory length: 33555   epsilon: 0.009999999999727473    steps: 1097     evaluation reward: 2.57 frames: 33555\n",
      "episode: 129   score: 3.0   memory length: 33811   epsilon: 0.009999999999727473    steps: 256     evaluation reward: 2.58 frames: 33811\n",
      "episode: 130   score: 7.0   memory length: 34282   epsilon: 0.009999999999727473    steps: 471     evaluation reward: 2.64 frames: 34282\n",
      "episode: 131   score: 7.0   memory length: 34592   epsilon: 0.009999999999727473    steps: 310     evaluation reward: 2.69 frames: 34592\n",
      "episode: 132   score: 9.0   memory length: 35374   epsilon: 0.009999999999727473    steps: 782     evaluation reward: 2.77 frames: 35374\n",
      "episode: 133   score: 7.0   memory length: 36037   epsilon: 0.009999999999727473    steps: 663     evaluation reward: 2.78 frames: 36037\n",
      "episode: 134   score: 7.0   memory length: 36743   epsilon: 0.009999999999727473    steps: 706     evaluation reward: 2.83 frames: 36743\n",
      "episode: 135   score: 7.0   memory length: 37426   epsilon: 0.009999999999727473    steps: 683     evaluation reward: 2.88 frames: 37426\n",
      "episode: 136   score: 7.0   memory length: 38354   epsilon: 0.009999999999727473    steps: 928     evaluation reward: 2.95 frames: 38354\n",
      "episode: 137   score: 14.0   memory length: 39394   epsilon: 0.009999999999727473    steps: 1040     evaluation reward: 3.09 frames: 39394\n",
      "episode: 138   score: 7.0   memory length: 39853   epsilon: 0.009999999999727473    steps: 459     evaluation reward: 3.13 frames: 39853\n",
      "episode: 139   score: 12.0   memory length: 40498   epsilon: 0.009999999999727473    steps: 645     evaluation reward: 3.24 frames: 40498\n",
      "episode: 140   score: 7.0   memory length: 41322   epsilon: 0.009999999999727473    steps: 824     evaluation reward: 3.29 frames: 41322\n",
      "episode: 141   score: 12.0   memory length: 42778   epsilon: 0.009999999999727473    steps: 1456     evaluation reward: 3.4 frames: 42778\n",
      "episode: 142   score: 5.0   memory length: 43129   epsilon: 0.009999999999727473    steps: 351     evaluation reward: 3.45 frames: 43129\n",
      "episode: 143   score: 4.0   memory length: 43629   epsilon: 0.009999999999727473    steps: 500     evaluation reward: 3.49 frames: 43629\n",
      "episode: 144   score: 12.0   memory length: 44783   epsilon: 0.009999999999727473    steps: 1154     evaluation reward: 3.6 frames: 44783\n",
      "episode: 145   score: 8.0   memory length: 45882   epsilon: 0.009999999999727473    steps: 1099     evaluation reward: 3.64 frames: 45882\n",
      "episode: 146   score: 12.0   memory length: 47670   epsilon: 0.009999999999727473    steps: 1788     evaluation reward: 3.76 frames: 47670\n",
      "episode: 147   score: 11.0   memory length: 48549   epsilon: 0.009999999999727473    steps: 879     evaluation reward: 3.87 frames: 48549\n",
      "now time :  2018-12-20 11:40:41.814603\n",
      "episode: 148   score: 9.0   memory length: 50920   epsilon: 0.009999999999727473    steps: 2371     evaluation reward: 3.95 frames: 50920\n",
      "episode: 149   score: 12.0   memory length: 52052   epsilon: 0.009999999999727473    steps: 1132     evaluation reward: 4.05 frames: 52052\n",
      "episode: 150   score: 11.0   memory length: 52849   epsilon: 0.009999999999727473    steps: 797     evaluation reward: 4.13 frames: 52849\n",
      "episode: 151   score: 7.0   memory length: 53334   epsilon: 0.009999999999727473    steps: 485     evaluation reward: 4.18 frames: 53334\n",
      "episode: 152   score: 7.0   memory length: 53996   epsilon: 0.009999999999727473    steps: 662     evaluation reward: 4.25 frames: 53996\n",
      "episode: 153   score: 11.0   memory length: 55379   epsilon: 0.009999999999727473    steps: 1383     evaluation reward: 4.36 frames: 55379\n",
      "episode: 154   score: 8.0   memory length: 56160   epsilon: 0.009999999999727473    steps: 781     evaluation reward: 4.44 frames: 56160\n",
      "episode: 155   score: 11.0   memory length: 56453   epsilon: 0.009999999999727473    steps: 293     evaluation reward: 4.54 frames: 56453\n",
      "episode: 156   score: 13.0   memory length: 57362   epsilon: 0.009999999999727473    steps: 909     evaluation reward: 4.65 frames: 57362\n",
      "episode: 157   score: 8.0   memory length: 58098   epsilon: 0.009999999999727473    steps: 736     evaluation reward: 4.73 frames: 58098\n",
      "episode: 158   score: 3.0   memory length: 58924   epsilon: 0.009999999999727473    steps: 826     evaluation reward: 4.74 frames: 58924\n",
      "episode: 159   score: 8.0   memory length: 60233   epsilon: 0.009999999999727473    steps: 1309     evaluation reward: 4.82 frames: 60233\n",
      "episode: 160   score: 12.0   memory length: 61154   epsilon: 0.009999999999727473    steps: 921     evaluation reward: 4.92 frames: 61154\n",
      "episode: 161   score: 8.0   memory length: 61690   epsilon: 0.009999999999727473    steps: 536     evaluation reward: 5.0 frames: 61690\n",
      "episode: 162   score: 4.0   memory length: 62073   epsilon: 0.009999999999727473    steps: 383     evaluation reward: 5.01 frames: 62073\n",
      "episode: 163   score: 6.0   memory length: 62732   epsilon: 0.009999999999727473    steps: 659     evaluation reward: 5.05 frames: 62732\n",
      "episode: 164   score: 12.0   memory length: 63713   epsilon: 0.009999999999727473    steps: 981     evaluation reward: 5.17 frames: 63713\n",
      "episode: 165   score: 4.0   memory length: 64057   epsilon: 0.009999999999727473    steps: 344     evaluation reward: 5.19 frames: 64057\n",
      "episode: 166   score: 8.0   memory length: 65258   epsilon: 0.009999999999727473    steps: 1201     evaluation reward: 5.24 frames: 65258\n",
      "episode: 167   score: 11.0   memory length: 66082   epsilon: 0.009999999999727473    steps: 824     evaluation reward: 5.31 frames: 66082\n",
      "episode: 168   score: 9.0   memory length: 67898   epsilon: 0.009999999999727473    steps: 1816     evaluation reward: 5.39 frames: 67898\n",
      "episode: 169   score: 10.0   memory length: 68635   epsilon: 0.009999999999727473    steps: 737     evaluation reward: 5.49 frames: 68635\n",
      "episode: 170   score: 5.0   memory length: 69101   epsilon: 0.009999999999727473    steps: 466     evaluation reward: 5.54 frames: 69101\n",
      "episode: 171   score: 5.0   memory length: 71089   epsilon: 0.009999999999727473    steps: 1988     evaluation reward: 5.59 frames: 71089\n",
      "episode: 172   score: 7.0   memory length: 71556   epsilon: 0.009999999999727473    steps: 467     evaluation reward: 5.64 frames: 71556\n",
      "episode: 173   score: 7.0   memory length: 72322   epsilon: 0.009999999999727473    steps: 766     evaluation reward: 5.69 frames: 72322\n",
      "episode: 174   score: 7.0   memory length: 72881   epsilon: 0.009999999999727473    steps: 559     evaluation reward: 5.73 frames: 72881\n",
      "episode: 175   score: 5.0   memory length: 73478   epsilon: 0.009999999999727473    steps: 597     evaluation reward: 5.76 frames: 73478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 176   score: 8.0   memory length: 74076   epsilon: 0.009999999999727473    steps: 598     evaluation reward: 5.82 frames: 74076\n",
      "episode: 177   score: 4.0   memory length: 74892   epsilon: 0.009999999999727473    steps: 816     evaluation reward: 5.81 frames: 74892\n",
      "episode: 178   score: 5.0   memory length: 75206   epsilon: 0.009999999999727473    steps: 314     evaluation reward: 5.85 frames: 75206\n",
      "episode: 179   score: 4.0   memory length: 77020   epsilon: 0.009999999999727473    steps: 1814     evaluation reward: 5.88 frames: 77020\n",
      "episode: 180   score: 7.0   memory length: 77980   epsilon: 0.009999999999727473    steps: 960     evaluation reward: 5.95 frames: 77980\n",
      "episode: 181   score: 9.0   memory length: 78970   epsilon: 0.009999999999727473    steps: 990     evaluation reward: 6.03 frames: 78970\n",
      "episode: 182   score: 9.0   memory length: 80141   epsilon: 0.009999999999727473    steps: 1171     evaluation reward: 6.09 frames: 80141\n",
      "episode: 183   score: 5.0   memory length: 80725   epsilon: 0.009999999999727473    steps: 584     evaluation reward: 6.03 frames: 80725\n",
      "episode: 184   score: 14.0   memory length: 82717   epsilon: 0.009999999999727473    steps: 1992     evaluation reward: 6.15 frames: 82717\n",
      "episode: 185   score: 7.0   memory length: 83531   epsilon: 0.009999999999727473    steps: 814     evaluation reward: 6.2 frames: 83531\n",
      "episode: 186   score: 4.0   memory length: 83860   epsilon: 0.009999999999727473    steps: 329     evaluation reward: 6.21 frames: 83860\n",
      "episode: 187   score: 13.0   memory length: 86290   epsilon: 0.009999999999727473    steps: 2430     evaluation reward: 6.33 frames: 86290\n",
      "episode: 188   score: 12.0   memory length: 87519   epsilon: 0.009999999999727473    steps: 1229     evaluation reward: 6.44 frames: 87519\n",
      "episode: 189   score: 11.0   memory length: 89214   epsilon: 0.009999999999727473    steps: 1695     evaluation reward: 6.55 frames: 89214\n",
      "episode: 190   score: 7.0   memory length: 89689   epsilon: 0.009999999999727473    steps: 475     evaluation reward: 6.58 frames: 89689\n",
      "episode: 191   score: 5.0   memory length: 90168   epsilon: 0.009999999999727473    steps: 479     evaluation reward: 6.62 frames: 90168\n",
      "episode: 192   score: 7.0   memory length: 91538   epsilon: 0.009999999999727473    steps: 1370     evaluation reward: 6.66 frames: 91538\n",
      "episode: 193   score: 13.0   memory length: 93606   epsilon: 0.009999999999727473    steps: 2068     evaluation reward: 6.76 frames: 93606\n",
      "episode: 194   score: 13.0   memory length: 94950   epsilon: 0.009999999999727473    steps: 1344     evaluation reward: 6.87 frames: 94950\n",
      "episode: 195   score: 13.0   memory length: 96050   epsilon: 0.009999999999727473    steps: 1100     evaluation reward: 6.98 frames: 96050\n",
      "episode: 196   score: 11.0   memory length: 97273   epsilon: 0.009999999999727473    steps: 1223     evaluation reward: 7.07 frames: 97273\n",
      "episode: 197   score: 9.0   memory length: 97689   epsilon: 0.009999999999727473    steps: 416     evaluation reward: 7.14 frames: 97689\n",
      "episode: 198   score: 6.0   memory length: 98262   epsilon: 0.009999999999727473    steps: 573     evaluation reward: 7.19 frames: 98262\n",
      "episode: 199   score: 6.0   memory length: 98618   epsilon: 0.009999999999727473    steps: 356     evaluation reward: 7.24 frames: 98618\n",
      "episode: 200   score: 10.0   memory length: 99686   epsilon: 0.009999999999727473    steps: 1068     evaluation reward: 7.31 frames: 99686\n",
      "now time :  2018-12-20 12:05:01.638061\n",
      "episode: 201   score: 7.0   memory length: 100708   epsilon: 0.009999999999727473    steps: 1022     evaluation reward: 7.37 frames: 100708\n",
      "episode: 202   score: 7.0   memory length: 102367   epsilon: 0.009999999999727473    steps: 1659     evaluation reward: 7.43 frames: 102367\n",
      "episode: 203   score: 7.0   memory length: 102881   epsilon: 0.009999999999727473    steps: 514     evaluation reward: 7.46 frames: 102881\n",
      "episode: 204   score: 12.0   memory length: 104258   epsilon: 0.009999999999727473    steps: 1377     evaluation reward: 7.57 frames: 104258\n",
      "episode: 205   score: 6.0   memory length: 105472   epsilon: 0.009999999999727473    steps: 1214     evaluation reward: 7.56 frames: 105472\n",
      "episode: 206   score: 8.0   memory length: 106226   epsilon: 0.009999999999727473    steps: 754     evaluation reward: 7.59 frames: 106226\n",
      "episode: 207   score: 12.0   memory length: 107585   epsilon: 0.009999999999727473    steps: 1359     evaluation reward: 7.67 frames: 107585\n",
      "episode: 208   score: 14.0   memory length: 109342   epsilon: 0.009999999999727473    steps: 1757     evaluation reward: 7.78 frames: 109342\n",
      "episode: 209   score: 11.0   memory length: 110165   epsilon: 0.009999999999727473    steps: 823     evaluation reward: 7.87 frames: 110165\n",
      "episode: 210   score: 7.0   memory length: 110795   epsilon: 0.009999999999727473    steps: 630     evaluation reward: 7.89 frames: 110795\n",
      "episode: 211   score: 8.0   memory length: 111330   epsilon: 0.009999999999727473    steps: 535     evaluation reward: 7.95 frames: 111330\n",
      "episode: 212   score: 3.0   memory length: 111968   epsilon: 0.009999999999727473    steps: 638     evaluation reward: 7.94 frames: 111968\n",
      "episode: 213   score: 8.0   memory length: 113809   epsilon: 0.009999999999727473    steps: 1841     evaluation reward: 7.99 frames: 113809\n",
      "episode: 214   score: 8.0   memory length: 115639   epsilon: 0.009999999999727473    steps: 1830     evaluation reward: 8.0 frames: 115639\n",
      "episode: 215   score: 4.0   memory length: 116183   epsilon: 0.009999999999727473    steps: 544     evaluation reward: 8.02 frames: 116183\n",
      "episode: 216   score: 4.0   memory length: 116864   epsilon: 0.009999999999727473    steps: 681     evaluation reward: 7.96 frames: 116864\n",
      "episode: 217   score: 7.0   memory length: 118761   epsilon: 0.009999999999727473    steps: 1897     evaluation reward: 8.01 frames: 118761\n",
      "episode: 218   score: 3.0   memory length: 119318   epsilon: 0.009999999999727473    steps: 557     evaluation reward: 8.01 frames: 119318\n",
      "episode: 219   score: 5.0   memory length: 120287   epsilon: 0.009999999999727473    steps: 969     evaluation reward: 8.03 frames: 120287\n",
      "episode: 220   score: 7.0   memory length: 120599   epsilon: 0.009999999999727473    steps: 312     evaluation reward: 8.03 frames: 120599\n",
      "episode: 221   score: 5.0   memory length: 121056   epsilon: 0.009999999999727473    steps: 457     evaluation reward: 7.99 frames: 121056\n",
      "episode: 222   score: 8.0   memory length: 122044   epsilon: 0.009999999999727473    steps: 988     evaluation reward: 8.03 frames: 122044\n",
      "episode: 223   score: 8.0   memory length: 123152   epsilon: 0.009999999999727473    steps: 1108     evaluation reward: 8.04 frames: 123152\n",
      "episode: 224   score: 4.0   memory length: 124281   epsilon: 0.009999999999727473    steps: 1129     evaluation reward: 8.0 frames: 124281\n",
      "episode: 225   score: 8.0   memory length: 125242   epsilon: 0.009999999999727473    steps: 961     evaluation reward: 8.0 frames: 125242\n",
      "episode: 226   score: 6.0   memory length: 125861   epsilon: 0.009999999999727473    steps: 619     evaluation reward: 7.99 frames: 125861\n",
      "episode: 227   score: 3.0   memory length: 127089   epsilon: 0.009999999999727473    steps: 1228     evaluation reward: 7.95 frames: 127089\n",
      "episode: 228   score: 9.0   memory length: 127845   epsilon: 0.009999999999727473    steps: 756     evaluation reward: 7.97 frames: 127845\n",
      "episode: 229   score: 9.0   memory length: 128475   epsilon: 0.009999999999727473    steps: 630     evaluation reward: 8.03 frames: 128475\n",
      "episode: 230   score: 9.0   memory length: 130475   epsilon: 0.009999999999727473    steps: 2000     evaluation reward: 8.05 frames: 130475\n",
      "episode: 231   score: 6.0   memory length: 131209   epsilon: 0.009999999999727473    steps: 734     evaluation reward: 8.04 frames: 131209\n",
      "episode: 232   score: 12.0   memory length: 132069   epsilon: 0.009999999999727473    steps: 860     evaluation reward: 8.07 frames: 132069\n",
      "episode: 233   score: 7.0   memory length: 132672   epsilon: 0.009999999999727473    steps: 603     evaluation reward: 8.07 frames: 132672\n",
      "episode: 234   score: 8.0   memory length: 133524   epsilon: 0.009999999999727473    steps: 852     evaluation reward: 8.08 frames: 133524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 235   score: 12.0   memory length: 134138   epsilon: 0.009999999999727473    steps: 614     evaluation reward: 8.13 frames: 134138\n",
      "episode: 236   score: 4.0   memory length: 134782   epsilon: 0.009999999999727473    steps: 644     evaluation reward: 8.1 frames: 134782\n",
      "episode: 237   score: 8.0   memory length: 135511   epsilon: 0.009999999999727473    steps: 729     evaluation reward: 8.04 frames: 135511\n",
      "episode: 238   score: 7.0   memory length: 136803   epsilon: 0.009999999999727473    steps: 1292     evaluation reward: 8.04 frames: 136803\n",
      "episode: 239   score: 7.0   memory length: 137579   epsilon: 0.009999999999727473    steps: 776     evaluation reward: 7.99 frames: 137579\n",
      "episode: 240   score: 4.0   memory length: 138397   epsilon: 0.009999999999727473    steps: 818     evaluation reward: 7.96 frames: 138397\n",
      "episode: 241   score: 6.0   memory length: 139267   epsilon: 0.009999999999727473    steps: 870     evaluation reward: 7.9 frames: 139267\n",
      "episode: 242   score: 3.0   memory length: 139682   epsilon: 0.009999999999727473    steps: 415     evaluation reward: 7.88 frames: 139682\n",
      "episode: 243   score: 11.0   memory length: 140563   epsilon: 0.009999999999727473    steps: 881     evaluation reward: 7.95 frames: 140563\n",
      "episode: 244   score: 6.0   memory length: 141299   epsilon: 0.009999999999727473    steps: 736     evaluation reward: 7.89 frames: 141299\n",
      "episode: 245   score: 7.0   memory length: 142120   epsilon: 0.009999999999727473    steps: 821     evaluation reward: 7.88 frames: 142120\n",
      "episode: 246   score: 11.0   memory length: 143074   epsilon: 0.009999999999727473    steps: 954     evaluation reward: 7.87 frames: 143074\n",
      "episode: 247   score: 6.0   memory length: 143934   epsilon: 0.009999999999727473    steps: 860     evaluation reward: 7.82 frames: 143934\n",
      "episode: 248   score: 14.0   memory length: 145701   epsilon: 0.009999999999727473    steps: 1767     evaluation reward: 7.87 frames: 145701\n",
      "episode: 249   score: 4.0   memory length: 146816   epsilon: 0.009999999999727473    steps: 1115     evaluation reward: 7.79 frames: 146816\n",
      "episode: 250   score: 7.0   memory length: 148550   epsilon: 0.009999999999727473    steps: 1734     evaluation reward: 7.75 frames: 148550\n",
      "episode: 251   score: 8.0   memory length: 149314   epsilon: 0.009999999999727473    steps: 764     evaluation reward: 7.76 frames: 149314\n",
      "now time :  2018-12-20 12:30:04.055371\n",
      "episode: 252   score: 8.0   memory length: 150520   epsilon: 0.009999999999727473    steps: 1206     evaluation reward: 7.77 frames: 150520\n",
      "episode: 253   score: 5.0   memory length: 151013   epsilon: 0.009999999999727473    steps: 493     evaluation reward: 7.71 frames: 151013\n",
      "episode: 254   score: 9.0   memory length: 151921   epsilon: 0.009999999999727473    steps: 908     evaluation reward: 7.72 frames: 151921\n",
      "episode: 255   score: 6.0   memory length: 152853   epsilon: 0.009999999999727473    steps: 932     evaluation reward: 7.67 frames: 152853\n",
      "episode: 256   score: 4.0   memory length: 153585   epsilon: 0.009999999999727473    steps: 732     evaluation reward: 7.58 frames: 153585\n",
      "episode: 257   score: 10.0   memory length: 154825   epsilon: 0.009999999999727473    steps: 1240     evaluation reward: 7.6 frames: 154825\n",
      "episode: 258   score: 3.0   memory length: 155139   epsilon: 0.009999999999727473    steps: 314     evaluation reward: 7.6 frames: 155139\n",
      "episode: 259   score: 10.0   memory length: 156239   epsilon: 0.009999999999727473    steps: 1100     evaluation reward: 7.62 frames: 156239\n",
      "episode: 260   score: 8.0   memory length: 157146   epsilon: 0.009999999999727473    steps: 907     evaluation reward: 7.58 frames: 157146\n",
      "episode: 261   score: 3.0   memory length: 157850   epsilon: 0.009999999999727473    steps: 704     evaluation reward: 7.53 frames: 157850\n",
      "episode: 262   score: 9.0   memory length: 158551   epsilon: 0.009999999999727473    steps: 701     evaluation reward: 7.58 frames: 158551\n",
      "episode: 263   score: 11.0   memory length: 159502   epsilon: 0.009999999999727473    steps: 951     evaluation reward: 7.63 frames: 159502\n",
      "episode: 264   score: 9.0   memory length: 161029   epsilon: 0.009999999999727473    steps: 1527     evaluation reward: 7.6 frames: 161029\n",
      "episode: 265   score: 5.0   memory length: 161665   epsilon: 0.009999999999727473    steps: 636     evaluation reward: 7.61 frames: 161665\n",
      "episode: 266   score: 3.0   memory length: 162078   epsilon: 0.009999999999727473    steps: 413     evaluation reward: 7.56 frames: 162078\n",
      "episode: 267   score: 2.0   memory length: 162767   epsilon: 0.009999999999727473    steps: 689     evaluation reward: 7.47 frames: 162767\n",
      "episode: 268   score: 17.0   memory length: 163979   epsilon: 0.009999999999727473    steps: 1212     evaluation reward: 7.55 frames: 163979\n",
      "episode: 269   score: 11.0   memory length: 165507   epsilon: 0.009999999999727473    steps: 1528     evaluation reward: 7.56 frames: 165507\n",
      "episode: 270   score: 7.0   memory length: 166628   epsilon: 0.009999999999727473    steps: 1121     evaluation reward: 7.58 frames: 166628\n",
      "episode: 271   score: 4.0   memory length: 167403   epsilon: 0.009999999999727473    steps: 775     evaluation reward: 7.57 frames: 167403\n",
      "episode: 272   score: 5.0   memory length: 167772   epsilon: 0.009999999999727473    steps: 369     evaluation reward: 7.55 frames: 167772\n",
      "episode: 273   score: 9.0   memory length: 169989   epsilon: 0.009999999999727473    steps: 2217     evaluation reward: 7.57 frames: 169989\n",
      "episode: 274   score: 13.0   memory length: 171022   epsilon: 0.009999999999727473    steps: 1033     evaluation reward: 7.63 frames: 171022\n",
      "episode: 275   score: 11.0   memory length: 172349   epsilon: 0.009999999999727473    steps: 1327     evaluation reward: 7.69 frames: 172349\n",
      "episode: 276   score: 3.0   memory length: 172937   epsilon: 0.009999999999727473    steps: 588     evaluation reward: 7.64 frames: 172937\n",
      "episode: 277   score: 3.0   memory length: 173434   epsilon: 0.009999999999727473    steps: 497     evaluation reward: 7.63 frames: 173434\n",
      "episode: 278   score: 6.0   memory length: 173995   epsilon: 0.009999999999727473    steps: 561     evaluation reward: 7.64 frames: 173995\n",
      "episode: 279   score: 7.0   memory length: 175013   epsilon: 0.009999999999727473    steps: 1018     evaluation reward: 7.67 frames: 175013\n",
      "episode: 280   score: 8.0   memory length: 175490   epsilon: 0.009999999999727473    steps: 477     evaluation reward: 7.68 frames: 175490\n",
      "episode: 281   score: 9.0   memory length: 176396   epsilon: 0.009999999999727473    steps: 906     evaluation reward: 7.68 frames: 176396\n",
      "episode: 282   score: 7.0   memory length: 176829   epsilon: 0.009999999999727473    steps: 433     evaluation reward: 7.66 frames: 176829\n",
      "episode: 283   score: 14.0   memory length: 177197   epsilon: 0.009999999999727473    steps: 368     evaluation reward: 7.75 frames: 177197\n",
      "episode: 284   score: 8.0   memory length: 177839   epsilon: 0.009999999999727473    steps: 642     evaluation reward: 7.69 frames: 177839\n",
      "episode: 285   score: 3.0   memory length: 178249   epsilon: 0.009999999999727473    steps: 410     evaluation reward: 7.65 frames: 178249\n",
      "episode: 286   score: 5.0   memory length: 179087   epsilon: 0.009999999999727473    steps: 838     evaluation reward: 7.66 frames: 179087\n",
      "episode: 287   score: 4.0   memory length: 179671   epsilon: 0.009999999999727473    steps: 584     evaluation reward: 7.57 frames: 179671\n",
      "episode: 288   score: 3.0   memory length: 180389   epsilon: 0.009999999999727473    steps: 718     evaluation reward: 7.48 frames: 180389\n",
      "episode: 289   score: 9.0   memory length: 181115   epsilon: 0.009999999999727473    steps: 726     evaluation reward: 7.46 frames: 181115\n",
      "episode: 290   score: 10.0   memory length: 183823   epsilon: 0.009999999999727473    steps: 2708     evaluation reward: 7.49 frames: 183823\n",
      "episode: 291   score: 10.0   memory length: 185555   epsilon: 0.009999999999727473    steps: 1732     evaluation reward: 7.54 frames: 185555\n",
      "episode: 292   score: 5.0   memory length: 186520   epsilon: 0.009999999999727473    steps: 965     evaluation reward: 7.52 frames: 186520\n",
      "episode: 293   score: 3.0   memory length: 187103   epsilon: 0.009999999999727473    steps: 583     evaluation reward: 7.42 frames: 187103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 294   score: 3.0   memory length: 187985   epsilon: 0.009999999999727473    steps: 882     evaluation reward: 7.32 frames: 187985\n",
      "episode: 295   score: 5.0   memory length: 188704   epsilon: 0.009999999999727473    steps: 719     evaluation reward: 7.24 frames: 188704\n",
      "episode: 296   score: 8.0   memory length: 190318   epsilon: 0.009999999999727473    steps: 1614     evaluation reward: 7.21 frames: 190318\n",
      "episode: 297   score: 3.0   memory length: 191299   epsilon: 0.009999999999727473    steps: 981     evaluation reward: 7.15 frames: 191299\n",
      "episode: 298   score: 4.0   memory length: 191941   epsilon: 0.009999999999727473    steps: 642     evaluation reward: 7.13 frames: 191941\n",
      "episode: 299   score: 9.0   memory length: 192879   epsilon: 0.009999999999727473    steps: 938     evaluation reward: 7.16 frames: 192879\n",
      "episode: 300   score: 8.0   memory length: 193526   epsilon: 0.009999999999727473    steps: 647     evaluation reward: 7.14 frames: 193526\n",
      "episode: 301   score: 6.0   memory length: 194733   epsilon: 0.009999999999727473    steps: 1207     evaluation reward: 7.13 frames: 194733\n",
      "episode: 302   score: 8.0   memory length: 195780   epsilon: 0.009999999999727473    steps: 1047     evaluation reward: 7.14 frames: 195780\n",
      "episode: 303   score: 12.0   memory length: 196913   epsilon: 0.009999999999727473    steps: 1133     evaluation reward: 7.19 frames: 196913\n",
      "episode: 304   score: 6.0   memory length: 198421   epsilon: 0.009999999999727473    steps: 1508     evaluation reward: 7.13 frames: 198421\n",
      "episode: 305   score: 9.0   memory length: 198846   epsilon: 0.009999999999727473    steps: 425     evaluation reward: 7.16 frames: 198846\n",
      "now time :  2018-12-20 12:55:59.516500\n",
      "episode: 306   score: 14.0   memory length: 201037   epsilon: 0.009999999999727473    steps: 2191     evaluation reward: 7.22 frames: 201037\n",
      "episode: 307   score: 10.0   memory length: 201494   epsilon: 0.009999999999727473    steps: 457     evaluation reward: 7.2 frames: 201494\n",
      "episode: 308   score: 5.0   memory length: 204343   epsilon: 0.009999999999727473    steps: 2849     evaluation reward: 7.11 frames: 204343\n",
      "episode: 309   score: 7.0   memory length: 205555   epsilon: 0.009999999999727473    steps: 1212     evaluation reward: 7.07 frames: 205555\n",
      "episode: 310   score: 3.0   memory length: 205917   epsilon: 0.009999999999727473    steps: 362     evaluation reward: 7.03 frames: 205917\n",
      "episode: 311   score: 14.0   memory length: 206976   epsilon: 0.009999999999727473    steps: 1059     evaluation reward: 7.09 frames: 206976\n",
      "episode: 312   score: 12.0   memory length: 207748   epsilon: 0.009999999999727473    steps: 772     evaluation reward: 7.18 frames: 207748\n",
      "episode: 313   score: 10.0   memory length: 208650   epsilon: 0.009999999999727473    steps: 902     evaluation reward: 7.2 frames: 208650\n",
      "episode: 314   score: 3.0   memory length: 209064   epsilon: 0.009999999999727473    steps: 414     evaluation reward: 7.15 frames: 209064\n",
      "episode: 315   score: 3.0   memory length: 209419   epsilon: 0.009999999999727473    steps: 355     evaluation reward: 7.14 frames: 209419\n",
      "episode: 316   score: 9.0   memory length: 210419   epsilon: 0.009999999999727473    steps: 1000     evaluation reward: 7.19 frames: 210419\n",
      "episode: 317   score: 12.0   memory length: 212400   epsilon: 0.009999999999727473    steps: 1981     evaluation reward: 7.24 frames: 212400\n",
      "episode: 318   score: 8.0   memory length: 213438   epsilon: 0.009999999999727473    steps: 1038     evaluation reward: 7.29 frames: 213438\n",
      "episode: 319   score: 5.0   memory length: 214600   epsilon: 0.009999999999727473    steps: 1162     evaluation reward: 7.29 frames: 214600\n",
      "episode: 320   score: 9.0   memory length: 215367   epsilon: 0.009999999999727473    steps: 767     evaluation reward: 7.31 frames: 215367\n",
      "episode: 321   score: 9.0   memory length: 216360   epsilon: 0.009999999999727473    steps: 993     evaluation reward: 7.35 frames: 216360\n",
      "episode: 322   score: 10.0   memory length: 218109   epsilon: 0.009999999999727473    steps: 1749     evaluation reward: 7.37 frames: 218109\n",
      "episode: 323   score: 16.0   memory length: 219903   epsilon: 0.009999999999727473    steps: 1794     evaluation reward: 7.45 frames: 219903\n",
      "episode: 324   score: 4.0   memory length: 220587   epsilon: 0.009999999999727473    steps: 684     evaluation reward: 7.45 frames: 220587\n",
      "episode: 325   score: 4.0   memory length: 221352   epsilon: 0.009999999999727473    steps: 765     evaluation reward: 7.41 frames: 221352\n",
      "episode: 326   score: 4.0   memory length: 223586   epsilon: 0.009999999999727473    steps: 2234     evaluation reward: 7.39 frames: 223586\n",
      "episode: 327   score: 2.0   memory length: 224369   epsilon: 0.009999999999727473    steps: 783     evaluation reward: 7.38 frames: 224369\n",
      "episode: 328   score: 7.0   memory length: 225347   epsilon: 0.009999999999727473    steps: 978     evaluation reward: 7.36 frames: 225347\n",
      "episode: 329   score: 4.0   memory length: 225761   epsilon: 0.009999999999727473    steps: 414     evaluation reward: 7.31 frames: 225761\n",
      "episode: 330   score: 9.0   memory length: 226477   epsilon: 0.009999999999727473    steps: 716     evaluation reward: 7.31 frames: 226477\n",
      "episode: 331   score: 8.0   memory length: 227354   epsilon: 0.009999999999727473    steps: 877     evaluation reward: 7.33 frames: 227354\n",
      "episode: 332   score: 12.0   memory length: 229200   epsilon: 0.009999999999727473    steps: 1846     evaluation reward: 7.33 frames: 229200\n",
      "episode: 333   score: 11.0   memory length: 230611   epsilon: 0.009999999999727473    steps: 1411     evaluation reward: 7.37 frames: 230611\n",
      "episode: 334   score: 9.0   memory length: 231375   epsilon: 0.009999999999727473    steps: 764     evaluation reward: 7.38 frames: 231375\n",
      "episode: 335   score: 12.0   memory length: 231873   epsilon: 0.009999999999727473    steps: 498     evaluation reward: 7.38 frames: 231873\n",
      "episode: 336   score: 16.0   memory length: 232888   epsilon: 0.009999999999727473    steps: 1015     evaluation reward: 7.5 frames: 232888\n",
      "episode: 337   score: 3.0   memory length: 233147   epsilon: 0.009999999999727473    steps: 259     evaluation reward: 7.45 frames: 233147\n",
      "episode: 338   score: 13.0   memory length: 233485   epsilon: 0.009999999999727473    steps: 338     evaluation reward: 7.51 frames: 233485\n",
      "episode: 339   score: 7.0   memory length: 234186   epsilon: 0.009999999999727473    steps: 701     evaluation reward: 7.51 frames: 234186\n",
      "episode: 340   score: 4.0   memory length: 234588   epsilon: 0.009999999999727473    steps: 402     evaluation reward: 7.51 frames: 234588\n",
      "episode: 341   score: 11.0   memory length: 235857   epsilon: 0.009999999999727473    steps: 1269     evaluation reward: 7.56 frames: 235857\n",
      "episode: 342   score: 6.0   memory length: 236459   epsilon: 0.009999999999727473    steps: 602     evaluation reward: 7.59 frames: 236459\n",
      "episode: 343   score: 17.0   memory length: 238275   epsilon: 0.009999999999727473    steps: 1816     evaluation reward: 7.65 frames: 238275\n",
      "episode: 344   score: 3.0   memory length: 239215   epsilon: 0.009999999999727473    steps: 940     evaluation reward: 7.62 frames: 239215\n",
      "episode: 345   score: 4.0   memory length: 240306   epsilon: 0.009999999999727473    steps: 1091     evaluation reward: 7.59 frames: 240306\n",
      "episode: 346   score: 3.0   memory length: 240894   epsilon: 0.009999999999727473    steps: 588     evaluation reward: 7.51 frames: 240894\n",
      "episode: 347   score: 9.0   memory length: 242093   epsilon: 0.009999999999727473    steps: 1199     evaluation reward: 7.54 frames: 242093\n",
      "episode: 348   score: 9.0   memory length: 242520   epsilon: 0.009999999999727473    steps: 427     evaluation reward: 7.49 frames: 242520\n",
      "episode: 349   score: 3.0   memory length: 244036   epsilon: 0.009999999999727473    steps: 1516     evaluation reward: 7.48 frames: 244036\n",
      "episode: 350   score: 7.0   memory length: 244450   epsilon: 0.009999999999727473    steps: 414     evaluation reward: 7.48 frames: 244450\n",
      "episode: 351   score: 3.0   memory length: 244868   epsilon: 0.009999999999727473    steps: 418     evaluation reward: 7.43 frames: 244868\n",
      "episode: 352   score: 8.0   memory length: 245450   epsilon: 0.009999999999727473    steps: 582     evaluation reward: 7.43 frames: 245450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 353   score: 5.0   memory length: 245963   epsilon: 0.009999999999727473    steps: 513     evaluation reward: 7.43 frames: 245963\n",
      "episode: 354   score: 2.0   memory length: 246479   epsilon: 0.009999999999727473    steps: 516     evaluation reward: 7.36 frames: 246479\n",
      "episode: 355   score: 12.0   memory length: 247073   epsilon: 0.009999999999727473    steps: 594     evaluation reward: 7.42 frames: 247073\n",
      "episode: 356   score: 3.0   memory length: 247951   epsilon: 0.009999999999727473    steps: 878     evaluation reward: 7.41 frames: 247951\n",
      "episode: 357   score: 3.0   memory length: 248872   epsilon: 0.009999999999727473    steps: 921     evaluation reward: 7.34 frames: 248872\n",
      "episode: 358   score: 7.0   memory length: 249392   epsilon: 0.009999999999727473    steps: 520     evaluation reward: 7.38 frames: 249392\n",
      "episode: 359   score: 3.0   memory length: 249724   epsilon: 0.009999999999727473    steps: 332     evaluation reward: 7.31 frames: 249724\n",
      "now time :  2018-12-20 13:23:03.553263\n",
      "episode: 360   score: 5.0   memory length: 250131   epsilon: 0.009999999999727473    steps: 407     evaluation reward: 7.28 frames: 250131\n",
      "episode: 361   score: 2.0   memory length: 251007   epsilon: 0.009999999999727473    steps: 876     evaluation reward: 7.27 frames: 251007\n",
      "episode: 362   score: 8.0   memory length: 252021   epsilon: 0.009999999999727473    steps: 1014     evaluation reward: 7.26 frames: 252021\n",
      "episode: 363   score: 11.0   memory length: 253143   epsilon: 0.009999999999727473    steps: 1122     evaluation reward: 7.26 frames: 253143\n",
      "episode: 364   score: 4.0   memory length: 254305   epsilon: 0.009999999999727473    steps: 1162     evaluation reward: 7.21 frames: 254305\n",
      "episode: 365   score: 6.0   memory length: 254856   epsilon: 0.009999999999727473    steps: 551     evaluation reward: 7.22 frames: 254856\n",
      "episode: 366   score: 8.0   memory length: 255389   epsilon: 0.009999999999727473    steps: 533     evaluation reward: 7.27 frames: 255389\n",
      "episode: 367   score: 11.0   memory length: 256572   epsilon: 0.009999999999727473    steps: 1183     evaluation reward: 7.36 frames: 256572\n",
      "episode: 368   score: 5.0   memory length: 257395   epsilon: 0.009999999999727473    steps: 823     evaluation reward: 7.24 frames: 257395\n",
      "episode: 369   score: 5.0   memory length: 258009   epsilon: 0.009999999999727473    steps: 614     evaluation reward: 7.18 frames: 258009\n",
      "episode: 370   score: 6.0   memory length: 260329   epsilon: 0.009999999999727473    steps: 2320     evaluation reward: 7.17 frames: 260329\n",
      "episode: 371   score: 7.0   memory length: 260904   epsilon: 0.009999999999727473    steps: 575     evaluation reward: 7.2 frames: 260904\n",
      "episode: 372   score: 5.0   memory length: 261429   epsilon: 0.009999999999727473    steps: 525     evaluation reward: 7.2 frames: 261429\n",
      "episode: 373   score: 3.0   memory length: 262965   epsilon: 0.009999999999727473    steps: 1536     evaluation reward: 7.14 frames: 262965\n",
      "episode: 374   score: 16.0   memory length: 264303   epsilon: 0.009999999999727473    steps: 1338     evaluation reward: 7.17 frames: 264303\n",
      "episode: 375   score: 8.0   memory length: 265276   epsilon: 0.009999999999727473    steps: 973     evaluation reward: 7.14 frames: 265276\n",
      "episode: 376   score: 4.0   memory length: 265743   epsilon: 0.009999999999727473    steps: 467     evaluation reward: 7.15 frames: 265743\n",
      "episode: 377   score: 8.0   memory length: 267381   epsilon: 0.009999999999727473    steps: 1638     evaluation reward: 7.2 frames: 267381\n",
      "episode: 378   score: 6.0   memory length: 267737   epsilon: 0.009999999999727473    steps: 356     evaluation reward: 7.2 frames: 267737\n",
      "episode: 379   score: 4.0   memory length: 268329   epsilon: 0.009999999999727473    steps: 592     evaluation reward: 7.17 frames: 268329\n",
      "episode: 380   score: 2.0   memory length: 269301   epsilon: 0.009999999999727473    steps: 972     evaluation reward: 7.11 frames: 269301\n",
      "episode: 381   score: 7.0   memory length: 270132   epsilon: 0.009999999999727473    steps: 831     evaluation reward: 7.09 frames: 270132\n",
      "episode: 382   score: 9.0   memory length: 270960   epsilon: 0.009999999999727473    steps: 828     evaluation reward: 7.11 frames: 270960\n",
      "episode: 383   score: 7.0   memory length: 271543   epsilon: 0.009999999999727473    steps: 583     evaluation reward: 7.04 frames: 271543\n",
      "episode: 384   score: 4.0   memory length: 272383   epsilon: 0.009999999999727473    steps: 840     evaluation reward: 7.0 frames: 272383\n",
      "episode: 385   score: 2.0   memory length: 272766   epsilon: 0.009999999999727473    steps: 383     evaluation reward: 6.99 frames: 272766\n",
      "episode: 386   score: 13.0   memory length: 273566   epsilon: 0.009999999999727473    steps: 800     evaluation reward: 7.07 frames: 273566\n",
      "episode: 387   score: 3.0   memory length: 274169   epsilon: 0.009999999999727473    steps: 603     evaluation reward: 7.06 frames: 274169\n",
      "episode: 388   score: 5.0   memory length: 274657   epsilon: 0.009999999999727473    steps: 488     evaluation reward: 7.08 frames: 274657\n",
      "episode: 389   score: 9.0   memory length: 275698   epsilon: 0.009999999999727473    steps: 1041     evaluation reward: 7.08 frames: 275698\n",
      "episode: 390   score: 1.0   memory length: 275883   epsilon: 0.009999999999727473    steps: 185     evaluation reward: 6.99 frames: 275883\n",
      "episode: 391   score: 7.0   memory length: 276279   epsilon: 0.009999999999727473    steps: 396     evaluation reward: 6.96 frames: 276279\n",
      "episode: 392   score: 3.0   memory length: 276599   epsilon: 0.009999999999727473    steps: 320     evaluation reward: 6.94 frames: 276599\n",
      "episode: 393   score: 5.0   memory length: 277046   epsilon: 0.009999999999727473    steps: 447     evaluation reward: 6.96 frames: 277046\n",
      "episode: 394   score: 13.0   memory length: 277675   epsilon: 0.009999999999727473    steps: 629     evaluation reward: 7.06 frames: 277675\n",
      "episode: 395   score: 4.0   memory length: 278419   epsilon: 0.009999999999727473    steps: 744     evaluation reward: 7.05 frames: 278419\n",
      "episode: 396   score: 10.0   memory length: 279742   epsilon: 0.009999999999727473    steps: 1323     evaluation reward: 7.07 frames: 279742\n",
      "episode: 397   score: 3.0   memory length: 280509   epsilon: 0.009999999999727473    steps: 767     evaluation reward: 7.07 frames: 280509\n",
      "episode: 398   score: 4.0   memory length: 281235   epsilon: 0.009999999999727473    steps: 726     evaluation reward: 7.07 frames: 281235\n",
      "episode: 399   score: 5.0   memory length: 281625   epsilon: 0.009999999999727473    steps: 390     evaluation reward: 7.03 frames: 281625\n",
      "episode: 400   score: 3.0   memory length: 282953   epsilon: 0.009999999999727473    steps: 1328     evaluation reward: 6.98 frames: 282953\n",
      "episode: 401   score: 8.0   memory length: 283648   epsilon: 0.009999999999727473    steps: 695     evaluation reward: 7.0 frames: 283648\n",
      "episode: 402   score: 2.0   memory length: 285186   epsilon: 0.009999999999727473    steps: 1538     evaluation reward: 6.94 frames: 285186\n",
      "episode: 403   score: 5.0   memory length: 286349   epsilon: 0.009999999999727473    steps: 1163     evaluation reward: 6.87 frames: 286349\n",
      "episode: 404   score: 4.0   memory length: 286904   epsilon: 0.009999999999727473    steps: 555     evaluation reward: 6.85 frames: 286904\n",
      "episode: 405   score: 1.0   memory length: 287674   epsilon: 0.009999999999727473    steps: 770     evaluation reward: 6.77 frames: 287674\n",
      "episode: 406   score: 4.0   memory length: 288357   epsilon: 0.009999999999727473    steps: 683     evaluation reward: 6.67 frames: 288357\n",
      "episode: 407   score: 5.0   memory length: 289135   epsilon: 0.009999999999727473    steps: 778     evaluation reward: 6.62 frames: 289135\n",
      "episode: 408   score: 3.0   memory length: 290026   epsilon: 0.009999999999727473    steps: 891     evaluation reward: 6.6 frames: 290026\n",
      "episode: 409   score: 7.0   memory length: 292187   epsilon: 0.009999999999727473    steps: 2161     evaluation reward: 6.6 frames: 292187\n",
      "episode: 410   score: 3.0   memory length: 293114   epsilon: 0.009999999999727473    steps: 927     evaluation reward: 6.6 frames: 293114\n",
      "episode: 411   score: 6.0   memory length: 294475   epsilon: 0.009999999999727473    steps: 1361     evaluation reward: 6.52 frames: 294475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 412   score: 6.0   memory length: 295667   epsilon: 0.009999999999727473    steps: 1192     evaluation reward: 6.46 frames: 295667\n",
      "episode: 413   score: 4.0   memory length: 297007   epsilon: 0.009999999999727473    steps: 1340     evaluation reward: 6.4 frames: 297007\n",
      "episode: 414   score: 9.0   memory length: 298249   epsilon: 0.009999999999727473    steps: 1242     evaluation reward: 6.46 frames: 298249\n",
      "episode: 415   score: 5.0   memory length: 299287   epsilon: 0.009999999999727473    steps: 1038     evaluation reward: 6.48 frames: 299287\n",
      "episode: 416   score: 4.0   memory length: 299882   epsilon: 0.009999999999727473    steps: 595     evaluation reward: 6.43 frames: 299882\n",
      "now time :  2018-12-20 13:51:35.973675\n",
      "episode: 417   score: 9.0   memory length: 300603   epsilon: 0.009999999999727473    steps: 721     evaluation reward: 6.4 frames: 300603\n",
      "episode: 418   score: 9.0   memory length: 301715   epsilon: 0.009999999999727473    steps: 1112     evaluation reward: 6.41 frames: 301715\n",
      "episode: 419   score: 6.0   memory length: 302517   epsilon: 0.009999999999727473    steps: 802     evaluation reward: 6.42 frames: 302517\n",
      "episode: 420   score: 6.0   memory length: 303208   epsilon: 0.009999999999727473    steps: 691     evaluation reward: 6.39 frames: 303208\n",
      "episode: 421   score: 3.0   memory length: 303587   epsilon: 0.009999999999727473    steps: 379     evaluation reward: 6.33 frames: 303587\n",
      "episode: 422   score: 2.0   memory length: 304060   epsilon: 0.009999999999727473    steps: 473     evaluation reward: 6.25 frames: 304060\n",
      "episode: 423   score: 5.0   memory length: 304719   epsilon: 0.009999999999727473    steps: 659     evaluation reward: 6.14 frames: 304719\n",
      "episode: 424   score: 9.0   memory length: 305336   epsilon: 0.009999999999727473    steps: 617     evaluation reward: 6.19 frames: 305336\n",
      "episode: 425   score: 6.0   memory length: 305831   epsilon: 0.009999999999727473    steps: 495     evaluation reward: 6.21 frames: 305831\n",
      "episode: 426   score: 5.0   memory length: 307259   epsilon: 0.009999999999727473    steps: 1428     evaluation reward: 6.22 frames: 307259\n",
      "episode: 427   score: 10.0   memory length: 308340   epsilon: 0.009999999999727473    steps: 1081     evaluation reward: 6.3 frames: 308340\n",
      "episode: 428   score: 12.0   memory length: 309774   epsilon: 0.009999999999727473    steps: 1434     evaluation reward: 6.35 frames: 309774\n",
      "episode: 429   score: 2.0   memory length: 310741   epsilon: 0.009999999999727473    steps: 967     evaluation reward: 6.33 frames: 310741\n",
      "episode: 430   score: 5.0   memory length: 311867   epsilon: 0.009999999999727473    steps: 1126     evaluation reward: 6.29 frames: 311867\n",
      "episode: 431   score: 8.0   memory length: 312982   epsilon: 0.009999999999727473    steps: 1115     evaluation reward: 6.29 frames: 312982\n",
      "episode: 432   score: 3.0   memory length: 313863   epsilon: 0.009999999999727473    steps: 881     evaluation reward: 6.2 frames: 313863\n",
      "episode: 433   score: 7.0   memory length: 314206   epsilon: 0.009999999999727473    steps: 343     evaluation reward: 6.16 frames: 314206\n",
      "episode: 434   score: 13.0   memory length: 316540   epsilon: 0.009999999999727473    steps: 2334     evaluation reward: 6.2 frames: 316540\n",
      "episode: 435   score: 12.0   memory length: 317157   epsilon: 0.009999999999727473    steps: 617     evaluation reward: 6.2 frames: 317157\n",
      "episode: 436   score: 16.0   memory length: 318829   epsilon: 0.009999999999727473    steps: 1672     evaluation reward: 6.2 frames: 318829\n",
      "episode: 437   score: 5.0   memory length: 320579   epsilon: 0.009999999999727473    steps: 1750     evaluation reward: 6.22 frames: 320579\n",
      "episode: 438   score: 9.0   memory length: 321731   epsilon: 0.009999999999727473    steps: 1152     evaluation reward: 6.18 frames: 321731\n",
      "episode: 439   score: 7.0   memory length: 322419   epsilon: 0.009999999999727473    steps: 688     evaluation reward: 6.18 frames: 322419\n",
      "episode: 440   score: 16.0   memory length: 323465   epsilon: 0.009999999999727473    steps: 1046     evaluation reward: 6.3 frames: 323465\n",
      "episode: 441   score: 6.0   memory length: 324695   epsilon: 0.009999999999727473    steps: 1230     evaluation reward: 6.25 frames: 324695\n",
      "episode: 442   score: 4.0   memory length: 325493   epsilon: 0.009999999999727473    steps: 798     evaluation reward: 6.23 frames: 325493\n",
      "episode: 443   score: 9.0   memory length: 325959   epsilon: 0.009999999999727473    steps: 466     evaluation reward: 6.15 frames: 325959\n",
      "episode: 444   score: 14.0   memory length: 326814   epsilon: 0.009999999999727473    steps: 855     evaluation reward: 6.26 frames: 326814\n",
      "episode: 445   score: 8.0   memory length: 327958   epsilon: 0.009999999999727473    steps: 1144     evaluation reward: 6.3 frames: 327958\n",
      "episode: 446   score: 14.0   memory length: 329827   epsilon: 0.009999999999727473    steps: 1869     evaluation reward: 6.41 frames: 329827\n",
      "episode: 447   score: 14.0   memory length: 331449   epsilon: 0.009999999999727473    steps: 1622     evaluation reward: 6.46 frames: 331449\n",
      "episode: 448   score: 8.0   memory length: 332813   epsilon: 0.009999999999727473    steps: 1364     evaluation reward: 6.45 frames: 332813\n",
      "episode: 449   score: 9.0   memory length: 333178   epsilon: 0.009999999999727473    steps: 365     evaluation reward: 6.51 frames: 333178\n",
      "episode: 450   score: 8.0   memory length: 334701   epsilon: 0.009999999999727473    steps: 1523     evaluation reward: 6.52 frames: 334701\n",
      "episode: 451   score: 12.0   memory length: 335689   epsilon: 0.009999999999727473    steps: 988     evaluation reward: 6.61 frames: 335689\n",
      "episode: 452   score: 12.0   memory length: 337396   epsilon: 0.009999999999727473    steps: 1707     evaluation reward: 6.65 frames: 337396\n",
      "episode: 453   score: 10.0   memory length: 338092   epsilon: 0.009999999999727473    steps: 696     evaluation reward: 6.7 frames: 338092\n",
      "episode: 454   score: 9.0   memory length: 338893   epsilon: 0.009999999999727473    steps: 801     evaluation reward: 6.77 frames: 338893\n",
      "episode: 455   score: 12.0   memory length: 339708   epsilon: 0.009999999999727473    steps: 815     evaluation reward: 6.77 frames: 339708\n",
      "episode: 456   score: 5.0   memory length: 340236   epsilon: 0.009999999999727473    steps: 528     evaluation reward: 6.79 frames: 340236\n",
      "episode: 457   score: 5.0   memory length: 340706   epsilon: 0.009999999999727473    steps: 470     evaluation reward: 6.81 frames: 340706\n",
      "episode: 458   score: 6.0   memory length: 341004   epsilon: 0.009999999999727473    steps: 298     evaluation reward: 6.8 frames: 341004\n",
      "episode: 459   score: 7.0   memory length: 342131   epsilon: 0.009999999999727473    steps: 1127     evaluation reward: 6.84 frames: 342131\n",
      "episode: 460   score: 14.0   memory length: 342795   epsilon: 0.009999999999727473    steps: 664     evaluation reward: 6.93 frames: 342795\n",
      "episode: 461   score: 4.0   memory length: 345368   epsilon: 0.009999999999727473    steps: 2573     evaluation reward: 6.95 frames: 345368\n",
      "episode: 462   score: 5.0   memory length: 346292   epsilon: 0.009999999999727473    steps: 924     evaluation reward: 6.92 frames: 346292\n",
      "episode: 463   score: 10.0   memory length: 348197   epsilon: 0.009999999999727473    steps: 1905     evaluation reward: 6.91 frames: 348197\n",
      "episode: 464   score: 4.0   memory length: 348648   epsilon: 0.009999999999727473    steps: 451     evaluation reward: 6.91 frames: 348648\n",
      "episode: 465   score: 7.0   memory length: 349294   epsilon: 0.009999999999727473    steps: 646     evaluation reward: 6.92 frames: 349294\n",
      "now time :  2018-12-20 14:21:53.994397\n",
      "episode: 466   score: 4.0   memory length: 350171   epsilon: 0.009999999999727473    steps: 877     evaluation reward: 6.88 frames: 350171\n",
      "episode: 467   score: 12.0   memory length: 350690   epsilon: 0.009999999999727473    steps: 519     evaluation reward: 6.89 frames: 350690\n",
      "episode: 468   score: 4.0   memory length: 350993   epsilon: 0.009999999999727473    steps: 303     evaluation reward: 6.88 frames: 350993\n",
      "episode: 469   score: 10.0   memory length: 351911   epsilon: 0.009999999999727473    steps: 918     evaluation reward: 6.93 frames: 351911\n",
      "episode: 470   score: 8.0   memory length: 353238   epsilon: 0.009999999999727473    steps: 1327     evaluation reward: 6.95 frames: 353238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 471   score: 14.0   memory length: 353747   epsilon: 0.009999999999727473    steps: 509     evaluation reward: 7.02 frames: 353747\n",
      "episode: 472   score: 5.0   memory length: 354432   epsilon: 0.009999999999727473    steps: 685     evaluation reward: 7.02 frames: 354432\n",
      "episode: 473   score: 8.0   memory length: 354726   epsilon: 0.009999999999727473    steps: 294     evaluation reward: 7.07 frames: 354726\n",
      "episode: 474   score: 7.0   memory length: 355872   epsilon: 0.009999999999727473    steps: 1146     evaluation reward: 6.98 frames: 355872\n",
      "episode: 475   score: 3.0   memory length: 357195   epsilon: 0.009999999999727473    steps: 1323     evaluation reward: 6.93 frames: 357195\n",
      "episode: 476   score: 6.0   memory length: 357875   epsilon: 0.009999999999727473    steps: 680     evaluation reward: 6.95 frames: 357875\n",
      "episode: 477   score: 10.0   memory length: 358952   epsilon: 0.009999999999727473    steps: 1077     evaluation reward: 6.97 frames: 358952\n",
      "episode: 478   score: 3.0   memory length: 359222   epsilon: 0.009999999999727473    steps: 270     evaluation reward: 6.94 frames: 359222\n",
      "episode: 479   score: 13.0   memory length: 360342   epsilon: 0.009999999999727473    steps: 1120     evaluation reward: 7.03 frames: 360342\n",
      "episode: 480   score: 3.0   memory length: 361990   epsilon: 0.009999999999727473    steps: 1648     evaluation reward: 7.04 frames: 361990\n",
      "episode: 481   score: 9.0   memory length: 364316   epsilon: 0.009999999999727473    steps: 2326     evaluation reward: 7.06 frames: 364316\n",
      "episode: 482   score: 12.0   memory length: 365495   epsilon: 0.009999999999727473    steps: 1179     evaluation reward: 7.09 frames: 365495\n",
      "episode: 483   score: 6.0   memory length: 365861   epsilon: 0.009999999999727473    steps: 366     evaluation reward: 7.08 frames: 365861\n",
      "episode: 484   score: 9.0   memory length: 367227   epsilon: 0.009999999999727473    steps: 1366     evaluation reward: 7.13 frames: 367227\n",
      "episode: 485   score: 4.0   memory length: 367491   epsilon: 0.009999999999727473    steps: 264     evaluation reward: 7.15 frames: 367491\n",
      "episode: 486   score: 6.0   memory length: 368073   epsilon: 0.009999999999727473    steps: 582     evaluation reward: 7.08 frames: 368073\n",
      "episode: 487   score: 3.0   memory length: 368707   epsilon: 0.009999999999727473    steps: 634     evaluation reward: 7.08 frames: 368707\n",
      "episode: 488   score: 13.0   memory length: 369085   epsilon: 0.009999999999727473    steps: 378     evaluation reward: 7.16 frames: 369085\n",
      "episode: 489   score: 11.0   memory length: 369977   epsilon: 0.009999999999727473    steps: 892     evaluation reward: 7.18 frames: 369977\n",
      "episode: 490   score: 9.0   memory length: 371171   epsilon: 0.009999999999727473    steps: 1194     evaluation reward: 7.26 frames: 371171\n",
      "episode: 491   score: 5.0   memory length: 371505   epsilon: 0.009999999999727473    steps: 334     evaluation reward: 7.24 frames: 371505\n",
      "episode: 492   score: 5.0   memory length: 372049   epsilon: 0.009999999999727473    steps: 544     evaluation reward: 7.26 frames: 372049\n",
      "episode: 493   score: 4.0   memory length: 372851   epsilon: 0.009999999999727473    steps: 802     evaluation reward: 7.25 frames: 372851\n",
      "episode: 494   score: 4.0   memory length: 373530   epsilon: 0.009999999999727473    steps: 679     evaluation reward: 7.16 frames: 373530\n",
      "episode: 495   score: 5.0   memory length: 373920   epsilon: 0.009999999999727473    steps: 390     evaluation reward: 7.17 frames: 373920\n",
      "episode: 496   score: 1.0   memory length: 374464   epsilon: 0.009999999999727473    steps: 544     evaluation reward: 7.08 frames: 374464\n",
      "episode: 497   score: 5.0   memory length: 374963   epsilon: 0.009999999999727473    steps: 499     evaluation reward: 7.1 frames: 374963\n",
      "episode: 498   score: 6.0   memory length: 375311   epsilon: 0.009999999999727473    steps: 348     evaluation reward: 7.12 frames: 375311\n",
      "episode: 499   score: 3.0   memory length: 376947   epsilon: 0.009999999999727473    steps: 1636     evaluation reward: 7.1 frames: 376947\n",
      "episode: 500   score: 5.0   memory length: 377412   epsilon: 0.009999999999727473    steps: 465     evaluation reward: 7.12 frames: 377412\n",
      "episode: 501   score: 7.0   memory length: 378188   epsilon: 0.009999999999727473    steps: 776     evaluation reward: 7.11 frames: 378188\n",
      "episode: 502   score: 13.0   memory length: 378748   epsilon: 0.009999999999727473    steps: 560     evaluation reward: 7.22 frames: 378748\n",
      "episode: 503   score: 11.0   memory length: 379802   epsilon: 0.009999999999727473    steps: 1054     evaluation reward: 7.28 frames: 379802\n",
      "episode: 504   score: 14.0   memory length: 380717   epsilon: 0.009999999999727473    steps: 915     evaluation reward: 7.38 frames: 380717\n",
      "episode: 505   score: 7.0   memory length: 381739   epsilon: 0.009999999999727473    steps: 1022     evaluation reward: 7.44 frames: 381739\n",
      "episode: 506   score: 8.0   memory length: 382333   epsilon: 0.009999999999727473    steps: 594     evaluation reward: 7.48 frames: 382333\n",
      "episode: 507   score: 5.0   memory length: 383065   epsilon: 0.009999999999727473    steps: 732     evaluation reward: 7.48 frames: 383065\n",
      "episode: 508   score: 5.0   memory length: 383525   epsilon: 0.009999999999727473    steps: 460     evaluation reward: 7.5 frames: 383525\n",
      "episode: 509   score: 3.0   memory length: 383834   epsilon: 0.009999999999727473    steps: 309     evaluation reward: 7.46 frames: 383834\n",
      "episode: 510   score: 8.0   memory length: 384274   epsilon: 0.009999999999727473    steps: 440     evaluation reward: 7.51 frames: 384274\n",
      "episode: 511   score: 9.0   memory length: 384974   epsilon: 0.009999999999727473    steps: 700     evaluation reward: 7.54 frames: 384974\n",
      "episode: 512   score: 8.0   memory length: 387401   epsilon: 0.009999999999727473    steps: 2427     evaluation reward: 7.56 frames: 387401\n",
      "episode: 513   score: 10.0   memory length: 387799   epsilon: 0.009999999999727473    steps: 398     evaluation reward: 7.62 frames: 387799\n",
      "episode: 514   score: 5.0   memory length: 388128   epsilon: 0.009999999999727473    steps: 329     evaluation reward: 7.58 frames: 388128\n",
      "episode: 515   score: 13.0   memory length: 388588   epsilon: 0.009999999999727473    steps: 460     evaluation reward: 7.66 frames: 388588\n",
      "episode: 516   score: 6.0   memory length: 389041   epsilon: 0.009999999999727473    steps: 453     evaluation reward: 7.68 frames: 389041\n",
      "episode: 517   score: 4.0   memory length: 389410   epsilon: 0.009999999999727473    steps: 369     evaluation reward: 7.63 frames: 389410\n",
      "episode: 518   score: 14.0   memory length: 390346   epsilon: 0.009999999999727473    steps: 936     evaluation reward: 7.68 frames: 390346\n",
      "episode: 519   score: 8.0   memory length: 391162   epsilon: 0.009999999999727473    steps: 816     evaluation reward: 7.7 frames: 391162\n",
      "episode: 520   score: 10.0   memory length: 391627   epsilon: 0.009999999999727473    steps: 465     evaluation reward: 7.74 frames: 391627\n",
      "episode: 521   score: 14.0   memory length: 392097   epsilon: 0.009999999999727473    steps: 470     evaluation reward: 7.85 frames: 392097\n",
      "episode: 522   score: 2.0   memory length: 392374   epsilon: 0.009999999999727473    steps: 277     evaluation reward: 7.85 frames: 392374\n",
      "episode: 523   score: 5.0   memory length: 393664   epsilon: 0.009999999999727473    steps: 1290     evaluation reward: 7.85 frames: 393664\n",
      "episode: 524   score: 13.0   memory length: 394782   epsilon: 0.009999999999727473    steps: 1118     evaluation reward: 7.89 frames: 394782\n",
      "episode: 525   score: 14.0   memory length: 395922   epsilon: 0.009999999999727473    steps: 1140     evaluation reward: 7.97 frames: 395922\n",
      "episode: 526   score: 2.0   memory length: 396249   epsilon: 0.009999999999727473    steps: 327     evaluation reward: 7.94 frames: 396249\n",
      "episode: 527   score: 5.0   memory length: 398211   epsilon: 0.009999999999727473    steps: 1962     evaluation reward: 7.89 frames: 398211\n",
      "episode: 528   score: 4.0   memory length: 399498   epsilon: 0.009999999999727473    steps: 1287     evaluation reward: 7.81 frames: 399498\n",
      "episode: 529   score: 4.0   memory length: 399779   epsilon: 0.009999999999727473    steps: 281     evaluation reward: 7.83 frames: 399779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now time :  2018-12-20 14:54:12.354810\n",
      "episode: 530   score: 5.0   memory length: 400100   epsilon: 0.009999999999727473    steps: 321     evaluation reward: 7.83 frames: 400100\n",
      "episode: 531   score: 9.0   memory length: 401041   epsilon: 0.009999999999727473    steps: 941     evaluation reward: 7.84 frames: 401041\n",
      "episode: 532   score: 5.0   memory length: 401857   epsilon: 0.009999999999727473    steps: 816     evaluation reward: 7.86 frames: 401857\n",
      "episode: 533   score: 6.0   memory length: 403062   epsilon: 0.009999999999727473    steps: 1205     evaluation reward: 7.85 frames: 403062\n",
      "episode: 534   score: 4.0   memory length: 403641   epsilon: 0.009999999999727473    steps: 579     evaluation reward: 7.76 frames: 403641\n",
      "episode: 535   score: 4.0   memory length: 404361   epsilon: 0.009999999999727473    steps: 720     evaluation reward: 7.68 frames: 404361\n",
      "episode: 536   score: 4.0   memory length: 404788   epsilon: 0.009999999999727473    steps: 427     evaluation reward: 7.56 frames: 404788\n",
      "episode: 537   score: 8.0   memory length: 405325   epsilon: 0.009999999999727473    steps: 537     evaluation reward: 7.59 frames: 405325\n",
      "episode: 538   score: 8.0   memory length: 406261   epsilon: 0.009999999999727473    steps: 936     evaluation reward: 7.58 frames: 406261\n",
      "episode: 539   score: 9.0   memory length: 407617   epsilon: 0.009999999999727473    steps: 1356     evaluation reward: 7.6 frames: 407617\n",
      "episode: 540   score: 12.0   memory length: 409002   epsilon: 0.009999999999727473    steps: 1385     evaluation reward: 7.56 frames: 409002\n",
      "episode: 541   score: 9.0   memory length: 409545   epsilon: 0.009999999999727473    steps: 543     evaluation reward: 7.59 frames: 409545\n",
      "episode: 542   score: 4.0   memory length: 409875   epsilon: 0.009999999999727473    steps: 330     evaluation reward: 7.59 frames: 409875\n",
      "episode: 543   score: 6.0   memory length: 410606   epsilon: 0.009999999999727473    steps: 731     evaluation reward: 7.56 frames: 410606\n",
      "episode: 544   score: 8.0   memory length: 411262   epsilon: 0.009999999999727473    steps: 656     evaluation reward: 7.5 frames: 411262\n",
      "episode: 545   score: 5.0   memory length: 412044   epsilon: 0.009999999999727473    steps: 782     evaluation reward: 7.47 frames: 412044\n",
      "episode: 546   score: 18.0   memory length: 413594   epsilon: 0.009999999999727473    steps: 1550     evaluation reward: 7.51 frames: 413594\n",
      "episode: 547   score: 16.0   memory length: 414317   epsilon: 0.009999999999727473    steps: 723     evaluation reward: 7.53 frames: 414317\n",
      "episode: 548   score: 9.0   memory length: 414990   epsilon: 0.009999999999727473    steps: 673     evaluation reward: 7.54 frames: 414990\n",
      "episode: 549   score: 4.0   memory length: 415631   epsilon: 0.009999999999727473    steps: 641     evaluation reward: 7.49 frames: 415631\n",
      "episode: 550   score: 4.0   memory length: 416669   epsilon: 0.009999999999727473    steps: 1038     evaluation reward: 7.45 frames: 416669\n",
      "episode: 551   score: 8.0   memory length: 417604   epsilon: 0.009999999999727473    steps: 935     evaluation reward: 7.41 frames: 417604\n",
      "episode: 552   score: 5.0   memory length: 417994   epsilon: 0.009999999999727473    steps: 390     evaluation reward: 7.34 frames: 417994\n",
      "episode: 553   score: 14.0   memory length: 418561   epsilon: 0.009999999999727473    steps: 567     evaluation reward: 7.38 frames: 418561\n",
      "episode: 554   score: 4.0   memory length: 419044   epsilon: 0.009999999999727473    steps: 483     evaluation reward: 7.33 frames: 419044\n",
      "episode: 555   score: 14.0   memory length: 420155   epsilon: 0.009999999999727473    steps: 1111     evaluation reward: 7.35 frames: 420155\n",
      "episode: 556   score: 8.0   memory length: 420498   epsilon: 0.009999999999727473    steps: 343     evaluation reward: 7.38 frames: 420498\n",
      "episode: 557   score: 5.0   memory length: 421116   epsilon: 0.009999999999727473    steps: 618     evaluation reward: 7.38 frames: 421116\n",
      "episode: 558   score: 11.0   memory length: 422391   epsilon: 0.009999999999727473    steps: 1275     evaluation reward: 7.43 frames: 422391\n",
      "episode: 559   score: 12.0   memory length: 423441   epsilon: 0.009999999999727473    steps: 1050     evaluation reward: 7.48 frames: 423441\n",
      "episode: 560   score: 10.0   memory length: 424573   epsilon: 0.009999999999727473    steps: 1132     evaluation reward: 7.44 frames: 424573\n",
      "episode: 561   score: 10.0   memory length: 425463   epsilon: 0.009999999999727473    steps: 890     evaluation reward: 7.5 frames: 425463\n",
      "episode: 562   score: 10.0   memory length: 425988   epsilon: 0.009999999999727473    steps: 525     evaluation reward: 7.55 frames: 425988\n",
      "episode: 563   score: 7.0   memory length: 426537   epsilon: 0.009999999999727473    steps: 549     evaluation reward: 7.52 frames: 426537\n",
      "episode: 564   score: 3.0   memory length: 427144   epsilon: 0.009999999999727473    steps: 607     evaluation reward: 7.51 frames: 427144\n",
      "episode: 565   score: 10.0   memory length: 427780   epsilon: 0.009999999999727473    steps: 636     evaluation reward: 7.54 frames: 427780\n",
      "episode: 566   score: 4.0   memory length: 428194   epsilon: 0.009999999999727473    steps: 414     evaluation reward: 7.54 frames: 428194\n",
      "episode: 567   score: 4.0   memory length: 428459   epsilon: 0.009999999999727473    steps: 265     evaluation reward: 7.46 frames: 428459\n",
      "episode: 568   score: 8.0   memory length: 429579   epsilon: 0.009999999999727473    steps: 1120     evaluation reward: 7.5 frames: 429579\n",
      "episode: 569   score: 5.0   memory length: 429919   epsilon: 0.009999999999727473    steps: 340     evaluation reward: 7.45 frames: 429919\n",
      "episode: 570   score: 13.0   memory length: 430427   epsilon: 0.009999999999727473    steps: 508     evaluation reward: 7.5 frames: 430427\n",
      "episode: 571   score: 7.0   memory length: 431642   epsilon: 0.009999999999727473    steps: 1215     evaluation reward: 7.43 frames: 431642\n",
      "episode: 572   score: 8.0   memory length: 432176   epsilon: 0.009999999999727473    steps: 534     evaluation reward: 7.46 frames: 432176\n",
      "episode: 573   score: 3.0   memory length: 433350   epsilon: 0.009999999999727473    steps: 1174     evaluation reward: 7.41 frames: 433350\n",
      "episode: 574   score: 10.0   memory length: 433946   epsilon: 0.009999999999727473    steps: 596     evaluation reward: 7.44 frames: 433946\n",
      "episode: 575   score: 5.0   memory length: 434231   epsilon: 0.009999999999727473    steps: 285     evaluation reward: 7.46 frames: 434231\n",
      "episode: 576   score: 5.0   memory length: 435391   epsilon: 0.009999999999727473    steps: 1160     evaluation reward: 7.45 frames: 435391\n",
      "episode: 577   score: 4.0   memory length: 436049   epsilon: 0.009999999999727473    steps: 658     evaluation reward: 7.39 frames: 436049\n",
      "episode: 578   score: 4.0   memory length: 436799   epsilon: 0.009999999999727473    steps: 750     evaluation reward: 7.4 frames: 436799\n",
      "episode: 579   score: 8.0   memory length: 437121   epsilon: 0.009999999999727473    steps: 322     evaluation reward: 7.35 frames: 437121\n",
      "episode: 580   score: 12.0   memory length: 437715   epsilon: 0.009999999999727473    steps: 594     evaluation reward: 7.44 frames: 437715\n",
      "episode: 581   score: 11.0   memory length: 438307   epsilon: 0.009999999999727473    steps: 592     evaluation reward: 7.46 frames: 438307\n",
      "episode: 582   score: 5.0   memory length: 438788   epsilon: 0.009999999999727473    steps: 481     evaluation reward: 7.39 frames: 438788\n",
      "episode: 583   score: 10.0   memory length: 439712   epsilon: 0.009999999999727473    steps: 924     evaluation reward: 7.43 frames: 439712\n",
      "episode: 584   score: 18.0   memory length: 441387   epsilon: 0.009999999999727473    steps: 1675     evaluation reward: 7.52 frames: 441387\n",
      "episode: 585   score: 6.0   memory length: 441860   epsilon: 0.009999999999727473    steps: 473     evaluation reward: 7.54 frames: 441860\n",
      "episode: 586   score: 3.0   memory length: 442838   epsilon: 0.009999999999727473    steps: 978     evaluation reward: 7.51 frames: 442838\n",
      "episode: 587   score: 13.0   memory length: 443440   epsilon: 0.009999999999727473    steps: 602     evaluation reward: 7.61 frames: 443440\n",
      "episode: 588   score: 8.0   memory length: 443792   epsilon: 0.009999999999727473    steps: 352     evaluation reward: 7.56 frames: 443792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 589   score: 17.0   memory length: 445612   epsilon: 0.009999999999727473    steps: 1820     evaluation reward: 7.62 frames: 445612\n",
      "episode: 590   score: 9.0   memory length: 447057   epsilon: 0.009999999999727473    steps: 1445     evaluation reward: 7.62 frames: 447057\n",
      "episode: 591   score: 6.0   memory length: 448050   epsilon: 0.009999999999727473    steps: 993     evaluation reward: 7.63 frames: 448050\n",
      "episode: 592   score: 6.0   memory length: 448570   epsilon: 0.009999999999727473    steps: 520     evaluation reward: 7.64 frames: 448570\n",
      "episode: 593   score: 10.0   memory length: 449332   epsilon: 0.009999999999727473    steps: 762     evaluation reward: 7.7 frames: 449332\n",
      "now time :  2018-12-20 15:28:13.541848\n",
      "episode: 594   score: 8.0   memory length: 450296   epsilon: 0.009999999999727473    steps: 964     evaluation reward: 7.74 frames: 450296\n",
      "episode: 595   score: 15.0   memory length: 452208   epsilon: 0.009999999999727473    steps: 1912     evaluation reward: 7.84 frames: 452208\n",
      "episode: 596   score: 7.0   memory length: 453430   epsilon: 0.009999999999727473    steps: 1222     evaluation reward: 7.9 frames: 453430\n",
      "episode: 597   score: 10.0   memory length: 454751   epsilon: 0.009999999999727473    steps: 1321     evaluation reward: 7.95 frames: 454751\n",
      "episode: 598   score: 6.0   memory length: 455128   epsilon: 0.009999999999727473    steps: 377     evaluation reward: 7.95 frames: 455128\n",
      "episode: 599   score: 8.0   memory length: 457094   epsilon: 0.009999999999727473    steps: 1966     evaluation reward: 8.0 frames: 457094\n",
      "episode: 600   score: 8.0   memory length: 458017   epsilon: 0.009999999999727473    steps: 923     evaluation reward: 8.03 frames: 458017\n",
      "episode: 601   score: 4.0   memory length: 458261   epsilon: 0.009999999999727473    steps: 244     evaluation reward: 8.0 frames: 458261\n",
      "episode: 602   score: 9.0   memory length: 458682   epsilon: 0.009999999999727473    steps: 421     evaluation reward: 7.96 frames: 458682\n",
      "episode: 603   score: 15.0   memory length: 459526   epsilon: 0.009999999999727473    steps: 844     evaluation reward: 8.0 frames: 459526\n",
      "episode: 604   score: 14.0   memory length: 460320   epsilon: 0.009999999999727473    steps: 794     evaluation reward: 8.0 frames: 460320\n",
      "episode: 605   score: 9.0   memory length: 460782   epsilon: 0.009999999999727473    steps: 462     evaluation reward: 8.02 frames: 460782\n",
      "episode: 606   score: 16.0   memory length: 462167   epsilon: 0.009999999999727473    steps: 1385     evaluation reward: 8.1 frames: 462167\n",
      "episode: 607   score: 9.0   memory length: 462991   epsilon: 0.009999999999727473    steps: 824     evaluation reward: 8.14 frames: 462991\n",
      "episode: 608   score: 15.0   memory length: 463991   epsilon: 0.009999999999727473    steps: 1000     evaluation reward: 8.24 frames: 463991\n",
      "episode: 609   score: 8.0   memory length: 464290   epsilon: 0.009999999999727473    steps: 299     evaluation reward: 8.29 frames: 464290\n",
      "episode: 610   score: 12.0   memory length: 464721   epsilon: 0.009999999999727473    steps: 431     evaluation reward: 8.33 frames: 464721\n",
      "episode: 611   score: 13.0   memory length: 465589   epsilon: 0.009999999999727473    steps: 868     evaluation reward: 8.37 frames: 465589\n",
      "episode: 612   score: 15.0   memory length: 466567   epsilon: 0.009999999999727473    steps: 978     evaluation reward: 8.44 frames: 466567\n",
      "episode: 613   score: 15.0   memory length: 467602   epsilon: 0.009999999999727473    steps: 1035     evaluation reward: 8.49 frames: 467602\n",
      "episode: 614   score: 5.0   memory length: 468718   epsilon: 0.009999999999727473    steps: 1116     evaluation reward: 8.49 frames: 468718\n",
      "episode: 615   score: 9.0   memory length: 469595   epsilon: 0.009999999999727473    steps: 877     evaluation reward: 8.45 frames: 469595\n",
      "episode: 616   score: 4.0   memory length: 470344   epsilon: 0.009999999999727473    steps: 749     evaluation reward: 8.43 frames: 470344\n",
      "episode: 617   score: 11.0   memory length: 471502   epsilon: 0.009999999999727473    steps: 1158     evaluation reward: 8.5 frames: 471502\n",
      "episode: 618   score: 9.0   memory length: 472060   epsilon: 0.009999999999727473    steps: 558     evaluation reward: 8.45 frames: 472060\n",
      "episode: 619   score: 15.0   memory length: 474700   epsilon: 0.009999999999727473    steps: 2640     evaluation reward: 8.52 frames: 474700\n",
      "episode: 620   score: 10.0   memory length: 475715   epsilon: 0.009999999999727473    steps: 1015     evaluation reward: 8.52 frames: 475715\n",
      "episode: 621   score: 4.0   memory length: 477527   epsilon: 0.009999999999727473    steps: 1812     evaluation reward: 8.42 frames: 477527\n",
      "episode: 622   score: 16.0   memory length: 478689   epsilon: 0.009999999999727473    steps: 1162     evaluation reward: 8.56 frames: 478689\n",
      "episode: 623   score: 7.0   memory length: 478935   epsilon: 0.009999999999727473    steps: 246     evaluation reward: 8.58 frames: 478935\n",
      "episode: 624   score: 10.0   memory length: 479282   epsilon: 0.009999999999727473    steps: 347     evaluation reward: 8.55 frames: 479282\n",
      "episode: 625   score: 16.0   memory length: 480098   epsilon: 0.009999999999727473    steps: 816     evaluation reward: 8.57 frames: 480098\n",
      "episode: 626   score: 12.0   memory length: 481312   epsilon: 0.009999999999727473    steps: 1214     evaluation reward: 8.67 frames: 481312\n",
      "episode: 627   score: 13.0   memory length: 482591   epsilon: 0.009999999999727473    steps: 1279     evaluation reward: 8.75 frames: 482591\n",
      "episode: 628   score: 12.0   memory length: 483666   epsilon: 0.009999999999727473    steps: 1075     evaluation reward: 8.83 frames: 483666\n",
      "episode: 629   score: 4.0   memory length: 484219   epsilon: 0.009999999999727473    steps: 553     evaluation reward: 8.83 frames: 484219\n",
      "episode: 630   score: 12.0   memory length: 484732   epsilon: 0.009999999999727473    steps: 513     evaluation reward: 8.9 frames: 484732\n",
      "episode: 631   score: 8.0   memory length: 485121   epsilon: 0.009999999999727473    steps: 389     evaluation reward: 8.89 frames: 485121\n",
      "episode: 632   score: 4.0   memory length: 486536   epsilon: 0.009999999999727473    steps: 1415     evaluation reward: 8.88 frames: 486536\n",
      "episode: 633   score: 8.0   memory length: 486812   epsilon: 0.009999999999727473    steps: 276     evaluation reward: 8.9 frames: 486812\n",
      "episode: 634   score: 20.0   memory length: 488271   epsilon: 0.009999999999727473    steps: 1459     evaluation reward: 9.06 frames: 488271\n",
      "episode: 635   score: 14.0   memory length: 489071   epsilon: 0.009999999999727473    steps: 800     evaluation reward: 9.16 frames: 489071\n",
      "episode: 636   score: 14.0   memory length: 489820   epsilon: 0.009999999999727473    steps: 749     evaluation reward: 9.26 frames: 489820\n",
      "episode: 637   score: 13.0   memory length: 490539   epsilon: 0.009999999999727473    steps: 719     evaluation reward: 9.31 frames: 490539\n",
      "episode: 638   score: 6.0   memory length: 491908   epsilon: 0.009999999999727473    steps: 1369     evaluation reward: 9.29 frames: 491908\n",
      "episode: 639   score: 5.0   memory length: 492675   epsilon: 0.009999999999727473    steps: 767     evaluation reward: 9.25 frames: 492675\n",
      "episode: 640   score: 14.0   memory length: 493621   epsilon: 0.009999999999727473    steps: 946     evaluation reward: 9.27 frames: 493621\n",
      "episode: 641   score: 14.0   memory length: 496296   epsilon: 0.009999999999727473    steps: 2675     evaluation reward: 9.32 frames: 496296\n",
      "episode: 642   score: 5.0   memory length: 496588   epsilon: 0.009999999999727473    steps: 292     evaluation reward: 9.33 frames: 496588\n",
      "episode: 643   score: 10.0   memory length: 496969   epsilon: 0.009999999999727473    steps: 381     evaluation reward: 9.37 frames: 496969\n",
      "episode: 644   score: 8.0   memory length: 497439   epsilon: 0.009999999999727473    steps: 470     evaluation reward: 9.37 frames: 497439\n",
      "episode: 645   score: 12.0   memory length: 497859   epsilon: 0.009999999999727473    steps: 420     evaluation reward: 9.44 frames: 497859\n",
      "episode: 646   score: 8.0   memory length: 499479   epsilon: 0.009999999999727473    steps: 1620     evaluation reward: 9.34 frames: 499479\n",
      "episode: 647   score: 7.0   memory length: 499916   epsilon: 0.009999999999727473    steps: 437     evaluation reward: 9.25 frames: 499916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now time :  2018-12-20 16:04:22.335554\n",
      "episode: 648   score: 7.0   memory length: 500620   epsilon: 0.009999999999727473    steps: 704     evaluation reward: 9.23 frames: 500620\n",
      "episode: 649   score: 6.0   memory length: 501092   epsilon: 0.009999999999727473    steps: 472     evaluation reward: 9.25 frames: 501092\n",
      "episode: 650   score: 15.0   memory length: 501883   epsilon: 0.009999999999727473    steps: 791     evaluation reward: 9.36 frames: 501883\n",
      "episode: 651   score: 12.0   memory length: 502849   epsilon: 0.009999999999727473    steps: 966     evaluation reward: 9.4 frames: 502849\n",
      "episode: 652   score: 5.0   memory length: 503466   epsilon: 0.009999999999727473    steps: 617     evaluation reward: 9.4 frames: 503466\n",
      "episode: 653   score: 5.0   memory length: 504101   epsilon: 0.009999999999727473    steps: 635     evaluation reward: 9.31 frames: 504101\n",
      "episode: 654   score: 7.0   memory length: 505031   epsilon: 0.009999999999727473    steps: 930     evaluation reward: 9.34 frames: 505031\n",
      "episode: 655   score: 9.0   memory length: 505576   epsilon: 0.009999999999727473    steps: 545     evaluation reward: 9.29 frames: 505576\n",
      "episode: 656   score: 6.0   memory length: 505920   epsilon: 0.009999999999727473    steps: 344     evaluation reward: 9.27 frames: 505920\n",
      "episode: 657   score: 8.0   memory length: 506564   epsilon: 0.009999999999727473    steps: 644     evaluation reward: 9.3 frames: 506564\n",
      "episode: 658   score: 8.0   memory length: 507635   epsilon: 0.009999999999727473    steps: 1071     evaluation reward: 9.27 frames: 507635\n",
      "episode: 659   score: 5.0   memory length: 507926   epsilon: 0.009999999999727473    steps: 291     evaluation reward: 9.2 frames: 507926\n",
      "episode: 660   score: 5.0   memory length: 508226   epsilon: 0.009999999999727473    steps: 300     evaluation reward: 9.15 frames: 508226\n",
      "episode: 661   score: 7.0   memory length: 509339   epsilon: 0.009999999999727473    steps: 1113     evaluation reward: 9.12 frames: 509339\n",
      "episode: 662   score: 7.0   memory length: 510758   epsilon: 0.009999999999727473    steps: 1419     evaluation reward: 9.09 frames: 510758\n",
      "episode: 663   score: 4.0   memory length: 511269   epsilon: 0.009999999999727473    steps: 511     evaluation reward: 9.06 frames: 511269\n",
      "episode: 664   score: 8.0   memory length: 511729   epsilon: 0.009999999999727473    steps: 460     evaluation reward: 9.11 frames: 511729\n",
      "episode: 665   score: 14.0   memory length: 512681   epsilon: 0.009999999999727473    steps: 952     evaluation reward: 9.15 frames: 512681\n",
      "episode: 666   score: 12.0   memory length: 513397   epsilon: 0.009999999999727473    steps: 716     evaluation reward: 9.23 frames: 513397\n",
      "episode: 667   score: 6.0   memory length: 514977   epsilon: 0.009999999999727473    steps: 1580     evaluation reward: 9.25 frames: 514977\n",
      "episode: 668   score: 8.0   memory length: 515375   epsilon: 0.009999999999727473    steps: 398     evaluation reward: 9.25 frames: 515375\n",
      "episode: 669   score: 4.0   memory length: 516575   epsilon: 0.009999999999727473    steps: 1200     evaluation reward: 9.24 frames: 516575\n",
      "episode: 670   score: 7.0   memory length: 517837   epsilon: 0.009999999999727473    steps: 1262     evaluation reward: 9.18 frames: 517837\n",
      "episode: 671   score: 3.0   memory length: 518206   epsilon: 0.009999999999727473    steps: 369     evaluation reward: 9.14 frames: 518206\n",
      "episode: 672   score: 8.0   memory length: 518623   epsilon: 0.009999999999727473    steps: 417     evaluation reward: 9.14 frames: 518623\n",
      "episode: 673   score: 14.0   memory length: 519270   epsilon: 0.009999999999727473    steps: 647     evaluation reward: 9.25 frames: 519270\n",
      "episode: 674   score: 3.0   memory length: 520262   epsilon: 0.009999999999727473    steps: 992     evaluation reward: 9.18 frames: 520262\n",
      "episode: 675   score: 7.0   memory length: 520929   epsilon: 0.009999999999727473    steps: 667     evaluation reward: 9.2 frames: 520929\n",
      "episode: 676   score: 5.0   memory length: 522325   epsilon: 0.009999999999727473    steps: 1396     evaluation reward: 9.2 frames: 522325\n",
      "episode: 677   score: 7.0   memory length: 522851   epsilon: 0.009999999999727473    steps: 526     evaluation reward: 9.23 frames: 522851\n",
      "episode: 678   score: 10.0   memory length: 523378   epsilon: 0.009999999999727473    steps: 527     evaluation reward: 9.29 frames: 523378\n",
      "episode: 679   score: 10.0   memory length: 524236   epsilon: 0.009999999999727473    steps: 858     evaluation reward: 9.31 frames: 524236\n",
      "episode: 680   score: 8.0   memory length: 526145   epsilon: 0.009999999999727473    steps: 1909     evaluation reward: 9.27 frames: 526145\n",
      "episode: 681   score: 12.0   memory length: 526882   epsilon: 0.009999999999727473    steps: 737     evaluation reward: 9.28 frames: 526882\n",
      "episode: 682   score: 4.0   memory length: 527165   epsilon: 0.009999999999727473    steps: 283     evaluation reward: 9.27 frames: 527165\n",
      "episode: 683   score: 5.0   memory length: 527609   epsilon: 0.009999999999727473    steps: 444     evaluation reward: 9.22 frames: 527609\n",
      "episode: 684   score: 5.0   memory length: 527971   epsilon: 0.009999999999727473    steps: 362     evaluation reward: 9.09 frames: 527971\n",
      "episode: 685   score: 16.0   memory length: 529011   epsilon: 0.009999999999727473    steps: 1040     evaluation reward: 9.19 frames: 529011\n",
      "episode: 686   score: 10.0   memory length: 529722   epsilon: 0.009999999999727473    steps: 711     evaluation reward: 9.26 frames: 529722\n",
      "episode: 687   score: 9.0   memory length: 531577   epsilon: 0.009999999999727473    steps: 1855     evaluation reward: 9.22 frames: 531577\n",
      "episode: 688   score: 11.0   memory length: 532901   epsilon: 0.009999999999727473    steps: 1324     evaluation reward: 9.25 frames: 532901\n",
      "episode: 689   score: 2.0   memory length: 534041   epsilon: 0.009999999999727473    steps: 1140     evaluation reward: 9.1 frames: 534041\n",
      "episode: 690   score: 18.0   memory length: 535004   epsilon: 0.009999999999727473    steps: 963     evaluation reward: 9.19 frames: 535004\n",
      "episode: 691   score: 3.0   memory length: 535687   epsilon: 0.009999999999727473    steps: 683     evaluation reward: 9.16 frames: 535687\n",
      "episode: 692   score: 10.0   memory length: 536066   epsilon: 0.009999999999727473    steps: 379     evaluation reward: 9.2 frames: 536066\n",
      "episode: 693   score: 2.0   memory length: 536266   epsilon: 0.009999999999727473    steps: 200     evaluation reward: 9.12 frames: 536266\n",
      "episode: 694   score: 13.0   memory length: 537025   epsilon: 0.009999999999727473    steps: 759     evaluation reward: 9.17 frames: 537025\n",
      "episode: 695   score: 9.0   memory length: 537468   epsilon: 0.009999999999727473    steps: 443     evaluation reward: 9.11 frames: 537468\n",
      "episode: 696   score: 15.0   memory length: 539590   epsilon: 0.009999999999727473    steps: 2122     evaluation reward: 9.19 frames: 539590\n",
      "episode: 697   score: 11.0   memory length: 539977   epsilon: 0.009999999999727473    steps: 387     evaluation reward: 9.2 frames: 539977\n",
      "episode: 698   score: 8.0   memory length: 541369   epsilon: 0.009999999999727473    steps: 1392     evaluation reward: 9.22 frames: 541369\n",
      "episode: 699   score: 2.0   memory length: 542458   epsilon: 0.009999999999727473    steps: 1089     evaluation reward: 9.16 frames: 542458\n",
      "episode: 700   score: 11.0   memory length: 543151   epsilon: 0.009999999999727473    steps: 693     evaluation reward: 9.19 frames: 543151\n",
      "episode: 701   score: 3.0   memory length: 543653   epsilon: 0.009999999999727473    steps: 502     evaluation reward: 9.18 frames: 543653\n",
      "episode: 702   score: 8.0   memory length: 544247   epsilon: 0.009999999999727473    steps: 594     evaluation reward: 9.17 frames: 544247\n",
      "episode: 703   score: 9.0   memory length: 544977   epsilon: 0.009999999999727473    steps: 730     evaluation reward: 9.11 frames: 544977\n",
      "episode: 704   score: 11.0   memory length: 545786   epsilon: 0.009999999999727473    steps: 809     evaluation reward: 9.08 frames: 545786\n",
      "episode: 705   score: 12.0   memory length: 546407   epsilon: 0.009999999999727473    steps: 621     evaluation reward: 9.11 frames: 546407\n",
      "episode: 706   score: 8.0   memory length: 547187   epsilon: 0.009999999999727473    steps: 780     evaluation reward: 9.03 frames: 547187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 707   score: 12.0   memory length: 547904   epsilon: 0.009999999999727473    steps: 717     evaluation reward: 9.06 frames: 547904\n",
      "episode: 708   score: 12.0   memory length: 549237   epsilon: 0.009999999999727473    steps: 1333     evaluation reward: 9.03 frames: 549237\n",
      "episode: 709   score: 8.0   memory length: 549530   epsilon: 0.009999999999727473    steps: 293     evaluation reward: 9.03 frames: 549530\n",
      "episode: 710   score: 5.0   memory length: 549861   epsilon: 0.009999999999727473    steps: 331     evaluation reward: 8.96 frames: 549861\n",
      "now time :  2018-12-20 16:43:13.046955\n",
      "episode: 711   score: 9.0   memory length: 550757   epsilon: 0.009999999999727473    steps: 896     evaluation reward: 8.92 frames: 550757\n",
      "episode: 712   score: 4.0   memory length: 552310   epsilon: 0.009999999999727473    steps: 1553     evaluation reward: 8.81 frames: 552310\n",
      "episode: 713   score: 8.0   memory length: 552707   epsilon: 0.009999999999727473    steps: 397     evaluation reward: 8.74 frames: 552707\n",
      "episode: 714   score: 5.0   memory length: 553369   epsilon: 0.009999999999727473    steps: 662     evaluation reward: 8.74 frames: 553369\n",
      "episode: 715   score: 5.0   memory length: 553657   epsilon: 0.009999999999727473    steps: 288     evaluation reward: 8.7 frames: 553657\n",
      "episode: 716   score: 3.0   memory length: 553869   epsilon: 0.009999999999727473    steps: 212     evaluation reward: 8.69 frames: 553869\n",
      "episode: 717   score: 7.0   memory length: 554449   epsilon: 0.009999999999727473    steps: 580     evaluation reward: 8.65 frames: 554449\n",
      "episode: 718   score: 3.0   memory length: 554677   epsilon: 0.009999999999727473    steps: 228     evaluation reward: 8.59 frames: 554677\n",
      "episode: 719   score: 5.0   memory length: 555052   epsilon: 0.009999999999727473    steps: 375     evaluation reward: 8.49 frames: 555052\n",
      "episode: 720   score: 8.0   memory length: 555745   epsilon: 0.009999999999727473    steps: 693     evaluation reward: 8.47 frames: 555745\n",
      "episode: 721   score: 3.0   memory length: 556021   epsilon: 0.009999999999727473    steps: 276     evaluation reward: 8.46 frames: 556021\n",
      "episode: 722   score: 8.0   memory length: 557708   epsilon: 0.009999999999727473    steps: 1687     evaluation reward: 8.38 frames: 557708\n",
      "episode: 723   score: 10.0   memory length: 558831   epsilon: 0.009999999999727473    steps: 1123     evaluation reward: 8.41 frames: 558831\n",
      "episode: 724   score: 17.0   memory length: 559455   epsilon: 0.009999999999727473    steps: 624     evaluation reward: 8.48 frames: 559455\n",
      "episode: 725   score: 12.0   memory length: 561085   epsilon: 0.009999999999727473    steps: 1630     evaluation reward: 8.44 frames: 561085\n",
      "episode: 726   score: 12.0   memory length: 561628   epsilon: 0.009999999999727473    steps: 543     evaluation reward: 8.44 frames: 561628\n",
      "episode: 727   score: 12.0   memory length: 562388   epsilon: 0.009999999999727473    steps: 760     evaluation reward: 8.43 frames: 562388\n",
      "episode: 728   score: 13.0   memory length: 563148   epsilon: 0.009999999999727473    steps: 760     evaluation reward: 8.44 frames: 563148\n",
      "episode: 729   score: 13.0   memory length: 564073   epsilon: 0.009999999999727473    steps: 925     evaluation reward: 8.53 frames: 564073\n",
      "episode: 730   score: 3.0   memory length: 564586   epsilon: 0.009999999999727473    steps: 513     evaluation reward: 8.44 frames: 564586\n",
      "episode: 731   score: 5.0   memory length: 565717   epsilon: 0.009999999999727473    steps: 1131     evaluation reward: 8.41 frames: 565717\n",
      "episode: 732   score: 7.0   memory length: 566570   epsilon: 0.009999999999727473    steps: 853     evaluation reward: 8.44 frames: 566570\n",
      "episode: 733   score: 4.0   memory length: 566816   epsilon: 0.009999999999727473    steps: 246     evaluation reward: 8.4 frames: 566816\n",
      "episode: 734   score: 2.0   memory length: 567881   epsilon: 0.009999999999727473    steps: 1065     evaluation reward: 8.22 frames: 567881\n",
      "episode: 735   score: 7.0   memory length: 568428   epsilon: 0.009999999999727473    steps: 547     evaluation reward: 8.15 frames: 568428\n",
      "episode: 736   score: 2.0   memory length: 569139   epsilon: 0.009999999999727473    steps: 711     evaluation reward: 8.03 frames: 569139\n",
      "episode: 737   score: 10.0   memory length: 570011   epsilon: 0.009999999999727473    steps: 872     evaluation reward: 8.0 frames: 570011\n",
      "episode: 738   score: 11.0   memory length: 570423   epsilon: 0.009999999999727473    steps: 412     evaluation reward: 8.05 frames: 570423\n",
      "episode: 739   score: 17.0   memory length: 570966   epsilon: 0.009999999999727473    steps: 543     evaluation reward: 8.17 frames: 570966\n",
      "episode: 740   score: 13.0   memory length: 571373   epsilon: 0.009999999999727473    steps: 407     evaluation reward: 8.16 frames: 571373\n",
      "episode: 741   score: 7.0   memory length: 571831   epsilon: 0.009999999999727473    steps: 458     evaluation reward: 8.09 frames: 571831\n",
      "episode: 742   score: 13.0   memory length: 572213   epsilon: 0.009999999999727473    steps: 382     evaluation reward: 8.17 frames: 572213\n",
      "episode: 743   score: 5.0   memory length: 572861   epsilon: 0.009999999999727473    steps: 648     evaluation reward: 8.12 frames: 572861\n",
      "episode: 744   score: 13.0   memory length: 574199   epsilon: 0.009999999999727473    steps: 1338     evaluation reward: 8.17 frames: 574199\n",
      "episode: 745   score: 12.0   memory length: 575826   epsilon: 0.009999999999727473    steps: 1627     evaluation reward: 8.17 frames: 575826\n",
      "episode: 746   score: 5.0   memory length: 576120   epsilon: 0.009999999999727473    steps: 294     evaluation reward: 8.14 frames: 576120\n",
      "episode: 747   score: 13.0   memory length: 576491   epsilon: 0.009999999999727473    steps: 371     evaluation reward: 8.2 frames: 576491\n",
      "episode: 748   score: 5.0   memory length: 577764   epsilon: 0.009999999999727473    steps: 1273     evaluation reward: 8.18 frames: 577764\n",
      "episode: 749   score: 8.0   memory length: 578193   epsilon: 0.009999999999727473    steps: 429     evaluation reward: 8.2 frames: 578193\n",
      "episode: 750   score: 3.0   memory length: 578440   epsilon: 0.009999999999727473    steps: 247     evaluation reward: 8.08 frames: 578440\n",
      "episode: 751   score: 8.0   memory length: 578806   epsilon: 0.009999999999727473    steps: 366     evaluation reward: 8.04 frames: 578806\n",
      "episode: 752   score: 9.0   memory length: 579158   epsilon: 0.009999999999727473    steps: 352     evaluation reward: 8.08 frames: 579158\n",
      "episode: 753   score: 8.0   memory length: 580213   epsilon: 0.009999999999727473    steps: 1055     evaluation reward: 8.11 frames: 580213\n",
      "episode: 754   score: 8.0   memory length: 580591   epsilon: 0.009999999999727473    steps: 378     evaluation reward: 8.12 frames: 580591\n",
      "episode: 755   score: 10.0   memory length: 581429   epsilon: 0.009999999999727473    steps: 838     evaluation reward: 8.13 frames: 581429\n",
      "episode: 756   score: 9.0   memory length: 582419   epsilon: 0.009999999999727473    steps: 990     evaluation reward: 8.16 frames: 582419\n",
      "episode: 757   score: 10.0   memory length: 583295   epsilon: 0.009999999999727473    steps: 876     evaluation reward: 8.18 frames: 583295\n",
      "episode: 758   score: 8.0   memory length: 584398   epsilon: 0.009999999999727473    steps: 1103     evaluation reward: 8.18 frames: 584398\n",
      "episode: 759   score: 2.0   memory length: 584793   epsilon: 0.009999999999727473    steps: 395     evaluation reward: 8.15 frames: 584793\n",
      "episode: 760   score: 9.0   memory length: 586527   epsilon: 0.009999999999727473    steps: 1734     evaluation reward: 8.19 frames: 586527\n",
      "episode: 761   score: 3.0   memory length: 586734   epsilon: 0.009999999999727473    steps: 207     evaluation reward: 8.15 frames: 586734\n",
      "episode: 762   score: 8.0   memory length: 587093   epsilon: 0.009999999999727473    steps: 359     evaluation reward: 8.16 frames: 587093\n",
      "episode: 763   score: 9.0   memory length: 587998   epsilon: 0.009999999999727473    steps: 905     evaluation reward: 8.21 frames: 587998\n",
      "episode: 764   score: 3.0   memory length: 588226   epsilon: 0.009999999999727473    steps: 228     evaluation reward: 8.16 frames: 588226\n",
      "episode: 765   score: 15.0   memory length: 588862   epsilon: 0.009999999999727473    steps: 636     evaluation reward: 8.17 frames: 588862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 766   score: 13.0   memory length: 589293   epsilon: 0.009999999999727473    steps: 431     evaluation reward: 8.18 frames: 589293\n",
      "episode: 767   score: 9.0   memory length: 590418   epsilon: 0.009999999999727473    steps: 1125     evaluation reward: 8.21 frames: 590418\n",
      "episode: 768   score: 12.0   memory length: 590968   epsilon: 0.009999999999727473    steps: 550     evaluation reward: 8.25 frames: 590968\n",
      "episode: 769   score: 8.0   memory length: 592642   epsilon: 0.009999999999727473    steps: 1674     evaluation reward: 8.29 frames: 592642\n",
      "episode: 770   score: 9.0   memory length: 592992   epsilon: 0.009999999999727473    steps: 350     evaluation reward: 8.31 frames: 592992\n",
      "episode: 771   score: 10.0   memory length: 593909   epsilon: 0.009999999999727473    steps: 917     evaluation reward: 8.38 frames: 593909\n",
      "episode: 772   score: 14.0   memory length: 595005   epsilon: 0.009999999999727473    steps: 1096     evaluation reward: 8.44 frames: 595005\n",
      "episode: 773   score: 5.0   memory length: 597103   epsilon: 0.009999999999727473    steps: 2098     evaluation reward: 8.35 frames: 597103\n",
      "episode: 774   score: 9.0   memory length: 598115   epsilon: 0.009999999999727473    steps: 1012     evaluation reward: 8.41 frames: 598115\n",
      "episode: 775   score: 9.0   memory length: 599412   epsilon: 0.009999999999727473    steps: 1297     evaluation reward: 8.43 frames: 599412\n",
      "episode: 776   score: 6.0   memory length: 599842   epsilon: 0.009999999999727473    steps: 430     evaluation reward: 8.44 frames: 599842\n",
      "now time :  2018-12-20 17:23:08.714210\n",
      "episode: 777   score: 9.0   memory length: 600256   epsilon: 0.009999999999727473    steps: 414     evaluation reward: 8.46 frames: 600256\n",
      "episode: 778   score: 10.0   memory length: 600796   epsilon: 0.009999999999727473    steps: 540     evaluation reward: 8.46 frames: 600796\n",
      "episode: 779   score: 8.0   memory length: 601137   epsilon: 0.009999999999727473    steps: 341     evaluation reward: 8.44 frames: 601137\n",
      "episode: 780   score: 5.0   memory length: 602323   epsilon: 0.009999999999727473    steps: 1186     evaluation reward: 8.41 frames: 602323\n",
      "episode: 781   score: 13.0   memory length: 602834   epsilon: 0.009999999999727473    steps: 511     evaluation reward: 8.42 frames: 602834\n",
      "episode: 782   score: 11.0   memory length: 603977   epsilon: 0.009999999999727473    steps: 1143     evaluation reward: 8.49 frames: 603977\n",
      "episode: 783   score: 5.0   memory length: 605604   epsilon: 0.009999999999727473    steps: 1627     evaluation reward: 8.49 frames: 605604\n",
      "episode: 784   score: 17.0   memory length: 607169   epsilon: 0.009999999999727473    steps: 1565     evaluation reward: 8.61 frames: 607169\n",
      "episode: 785   score: 14.0   memory length: 607519   epsilon: 0.009999999999727473    steps: 350     evaluation reward: 8.59 frames: 607519\n",
      "episode: 786   score: 8.0   memory length: 608681   epsilon: 0.009999999999727473    steps: 1162     evaluation reward: 8.57 frames: 608681\n",
      "episode: 787   score: 16.0   memory length: 609336   epsilon: 0.009999999999727473    steps: 655     evaluation reward: 8.64 frames: 609336\n",
      "episode: 788   score: 10.0   memory length: 609747   epsilon: 0.009999999999727473    steps: 411     evaluation reward: 8.63 frames: 609747\n",
      "episode: 789   score: 12.0   memory length: 611257   epsilon: 0.009999999999727473    steps: 1510     evaluation reward: 8.73 frames: 611257\n",
      "episode: 790   score: 15.0   memory length: 611864   epsilon: 0.009999999999727473    steps: 607     evaluation reward: 8.7 frames: 611864\n",
      "episode: 791   score: 5.0   memory length: 612244   epsilon: 0.009999999999727473    steps: 380     evaluation reward: 8.72 frames: 612244\n",
      "episode: 792   score: 5.0   memory length: 612941   epsilon: 0.009999999999727473    steps: 697     evaluation reward: 8.67 frames: 612941\n",
      "episode: 793   score: 12.0   memory length: 614385   epsilon: 0.009999999999727473    steps: 1444     evaluation reward: 8.77 frames: 614385\n",
      "episode: 794   score: 16.0   memory length: 615290   epsilon: 0.009999999999727473    steps: 905     evaluation reward: 8.8 frames: 615290\n",
      "episode: 795   score: 4.0   memory length: 616452   epsilon: 0.009999999999727473    steps: 1162     evaluation reward: 8.75 frames: 616452\n",
      "episode: 796   score: 8.0   memory length: 617327   epsilon: 0.009999999999727473    steps: 875     evaluation reward: 8.68 frames: 617327\n",
      "episode: 797   score: 11.0   memory length: 617828   epsilon: 0.009999999999727473    steps: 501     evaluation reward: 8.68 frames: 617828\n",
      "episode: 798   score: 16.0   memory length: 618650   epsilon: 0.009999999999727473    steps: 822     evaluation reward: 8.76 frames: 618650\n",
      "episode: 799   score: 9.0   memory length: 619994   epsilon: 0.009999999999727473    steps: 1344     evaluation reward: 8.83 frames: 619994\n",
      "episode: 800   score: 4.0   memory length: 620499   epsilon: 0.009999999999727473    steps: 505     evaluation reward: 8.76 frames: 620499\n",
      "episode: 801   score: 15.0   memory length: 621288   epsilon: 0.009999999999727473    steps: 789     evaluation reward: 8.88 frames: 621288\n",
      "episode: 802   score: 7.0   memory length: 622304   epsilon: 0.009999999999727473    steps: 1016     evaluation reward: 8.87 frames: 622304\n",
      "episode: 803   score: 7.0   memory length: 622655   epsilon: 0.009999999999727473    steps: 351     evaluation reward: 8.85 frames: 622655\n",
      "episode: 804   score: 9.0   memory length: 623686   epsilon: 0.009999999999727473    steps: 1031     evaluation reward: 8.83 frames: 623686\n",
      "episode: 805   score: 5.0   memory length: 624373   epsilon: 0.009999999999727473    steps: 687     evaluation reward: 8.76 frames: 624373\n",
      "episode: 806   score: 9.0   memory length: 624910   epsilon: 0.009999999999727473    steps: 537     evaluation reward: 8.77 frames: 624910\n",
      "episode: 807   score: 17.0   memory length: 626243   epsilon: 0.009999999999727473    steps: 1333     evaluation reward: 8.82 frames: 626243\n",
      "episode: 808   score: 11.0   memory length: 627024   epsilon: 0.009999999999727473    steps: 781     evaluation reward: 8.81 frames: 627024\n",
      "episode: 809   score: 11.0   memory length: 628059   epsilon: 0.009999999999727473    steps: 1035     evaluation reward: 8.84 frames: 628059\n",
      "episode: 810   score: 14.0   memory length: 628762   epsilon: 0.009999999999727473    steps: 703     evaluation reward: 8.93 frames: 628762\n",
      "episode: 811   score: 13.0   memory length: 629293   epsilon: 0.009999999999727473    steps: 531     evaluation reward: 8.97 frames: 629293\n",
      "episode: 812   score: 5.0   memory length: 629659   epsilon: 0.009999999999727473    steps: 366     evaluation reward: 8.98 frames: 629659\n",
      "episode: 813   score: 10.0   memory length: 630051   epsilon: 0.009999999999727473    steps: 392     evaluation reward: 9.0 frames: 630051\n",
      "episode: 814   score: 9.0   memory length: 630404   epsilon: 0.009999999999727473    steps: 353     evaluation reward: 9.04 frames: 630404\n",
      "episode: 815   score: 6.0   memory length: 631811   epsilon: 0.009999999999727473    steps: 1407     evaluation reward: 9.05 frames: 631811\n",
      "episode: 816   score: 12.0   memory length: 632362   epsilon: 0.009999999999727473    steps: 551     evaluation reward: 9.14 frames: 632362\n",
      "episode: 817   score: 13.0   memory length: 634254   epsilon: 0.009999999999727473    steps: 1892     evaluation reward: 9.2 frames: 634254\n",
      "episode: 818   score: 12.0   memory length: 635367   epsilon: 0.009999999999727473    steps: 1113     evaluation reward: 9.29 frames: 635367\n",
      "episode: 819   score: 12.0   memory length: 636502   epsilon: 0.009999999999727473    steps: 1135     evaluation reward: 9.36 frames: 636502\n",
      "episode: 820   score: 14.0   memory length: 638327   epsilon: 0.009999999999727473    steps: 1825     evaluation reward: 9.42 frames: 638327\n",
      "episode: 821   score: 13.0   memory length: 639145   epsilon: 0.009999999999727473    steps: 818     evaluation reward: 9.52 frames: 639145\n",
      "episode: 822   score: 4.0   memory length: 639822   epsilon: 0.009999999999727473    steps: 677     evaluation reward: 9.48 frames: 639822\n",
      "episode: 823   score: 9.0   memory length: 641236   epsilon: 0.009999999999727473    steps: 1414     evaluation reward: 9.47 frames: 641236\n",
      "episode: 824   score: 17.0   memory length: 643114   epsilon: 0.009999999999727473    steps: 1878     evaluation reward: 9.47 frames: 643114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 825   score: 9.0   memory length: 644240   epsilon: 0.009999999999727473    steps: 1126     evaluation reward: 9.44 frames: 644240\n",
      "episode: 826   score: 9.0   memory length: 644832   epsilon: 0.009999999999727473    steps: 592     evaluation reward: 9.41 frames: 644832\n",
      "episode: 827   score: 9.0   memory length: 645144   epsilon: 0.009999999999727473    steps: 312     evaluation reward: 9.38 frames: 645144\n",
      "episode: 828   score: 15.0   memory length: 647333   epsilon: 0.009999999999727473    steps: 2189     evaluation reward: 9.4 frames: 647333\n",
      "episode: 829   score: 10.0   memory length: 648073   epsilon: 0.009999999999727473    steps: 740     evaluation reward: 9.37 frames: 648073\n",
      "episode: 830   score: 9.0   memory length: 648762   epsilon: 0.009999999999727473    steps: 689     evaluation reward: 9.43 frames: 648762\n",
      "now time :  2018-12-20 18:04:45.873272\n",
      "episode: 831   score: 10.0   memory length: 650271   epsilon: 0.009999999999727473    steps: 1509     evaluation reward: 9.48 frames: 650271\n",
      "episode: 832   score: 17.0   memory length: 650945   epsilon: 0.009999999999727473    steps: 674     evaluation reward: 9.58 frames: 650945\n",
      "episode: 833   score: 8.0   memory length: 652174   epsilon: 0.009999999999727473    steps: 1229     evaluation reward: 9.62 frames: 652174\n",
      "episode: 834   score: 8.0   memory length: 652840   epsilon: 0.009999999999727473    steps: 666     evaluation reward: 9.68 frames: 652840\n",
      "episode: 835   score: 10.0   memory length: 653550   epsilon: 0.009999999999727473    steps: 710     evaluation reward: 9.71 frames: 653550\n",
      "episode: 836   score: 5.0   memory length: 654125   epsilon: 0.009999999999727473    steps: 575     evaluation reward: 9.74 frames: 654125\n",
      "episode: 837   score: 10.0   memory length: 654510   epsilon: 0.009999999999727473    steps: 385     evaluation reward: 9.74 frames: 654510\n",
      "episode: 838   score: 12.0   memory length: 655475   epsilon: 0.009999999999727473    steps: 965     evaluation reward: 9.75 frames: 655475\n",
      "episode: 839   score: 9.0   memory length: 655907   epsilon: 0.009999999999727473    steps: 432     evaluation reward: 9.67 frames: 655907\n",
      "episode: 840   score: 10.0   memory length: 657984   epsilon: 0.009999999999727473    steps: 2077     evaluation reward: 9.64 frames: 657984\n",
      "episode: 841   score: 17.0   memory length: 659174   epsilon: 0.009999999999727473    steps: 1190     evaluation reward: 9.74 frames: 659174\n",
      "episode: 842   score: 9.0   memory length: 660590   epsilon: 0.009999999999727473    steps: 1416     evaluation reward: 9.7 frames: 660590\n",
      "episode: 843   score: 9.0   memory length: 661511   epsilon: 0.009999999999727473    steps: 921     evaluation reward: 9.74 frames: 661511\n",
      "episode: 844   score: 5.0   memory length: 661803   epsilon: 0.009999999999727473    steps: 292     evaluation reward: 9.66 frames: 661803\n",
      "episode: 845   score: 4.0   memory length: 662600   epsilon: 0.009999999999727473    steps: 797     evaluation reward: 9.58 frames: 662600\n",
      "episode: 846   score: 7.0   memory length: 662965   epsilon: 0.009999999999727473    steps: 365     evaluation reward: 9.6 frames: 662965\n",
      "episode: 847   score: 9.0   memory length: 663530   epsilon: 0.009999999999727473    steps: 565     evaluation reward: 9.56 frames: 663530\n",
      "episode: 848   score: 9.0   memory length: 664500   epsilon: 0.009999999999727473    steps: 970     evaluation reward: 9.6 frames: 664500\n",
      "episode: 849   score: 14.0   memory length: 665641   epsilon: 0.009999999999727473    steps: 1141     evaluation reward: 9.66 frames: 665641\n",
      "episode: 850   score: 13.0   memory length: 667163   epsilon: 0.009999999999727473    steps: 1522     evaluation reward: 9.76 frames: 667163\n",
      "episode: 851   score: 3.0   memory length: 667397   epsilon: 0.009999999999727473    steps: 234     evaluation reward: 9.71 frames: 667397\n",
      "episode: 852   score: 13.0   memory length: 668565   epsilon: 0.009999999999727473    steps: 1168     evaluation reward: 9.75 frames: 668565\n",
      "episode: 853   score: 14.0   memory length: 670114   epsilon: 0.009999999999727473    steps: 1549     evaluation reward: 9.81 frames: 670114\n",
      "episode: 854   score: 10.0   memory length: 671196   epsilon: 0.009999999999727473    steps: 1082     evaluation reward: 9.83 frames: 671196\n",
      "episode: 855   score: 14.0   memory length: 672416   epsilon: 0.009999999999727473    steps: 1220     evaluation reward: 9.87 frames: 672416\n",
      "episode: 856   score: 14.0   memory length: 673889   epsilon: 0.009999999999727473    steps: 1473     evaluation reward: 9.92 frames: 673889\n",
      "episode: 857   score: 16.0   memory length: 674994   epsilon: 0.009999999999727473    steps: 1105     evaluation reward: 9.98 frames: 674994\n",
      "episode: 858   score: 8.0   memory length: 676763   epsilon: 0.009999999999727473    steps: 1769     evaluation reward: 9.98 frames: 676763\n",
      "episode: 859   score: 14.0   memory length: 678415   epsilon: 0.009999999999727473    steps: 1652     evaluation reward: 10.1 frames: 678415\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Agent' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8b8803c2a3f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;31m# stop training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_reward\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./save_model/breakout_dqn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Agent' object has no attribute 'model'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for e in range(EPISODES):\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    history = np.zeros([5, 84, 84], dtype=np.uint8)\n",
    "    step = 0\n",
    "    d = False\n",
    "    state = env.reset()\n",
    "    life = number_lives\n",
    "\n",
    "    get_init_state(history, state)\n",
    "\n",
    "    while not done:\n",
    "        step += 1\n",
    "        frame += 1\n",
    "#        if render_breakout:\n",
    "#            env.render()\n",
    "\n",
    "        # Select and perform an action\n",
    "        action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n",
    "\n",
    "        \n",
    "        next_state, reward, done, info = env.step(action + 1)\n",
    "\n",
    "        frame_next_state = get_frame(next_state)\n",
    "        history[4, :, :] = frame_next_state\n",
    "        terminal_state = check_live(life, info['ale.lives'])\n",
    "\n",
    "        life = info['ale.lives']\n",
    "        r = np.clip(reward, -1, 1)\n",
    "\n",
    "        # Store the transition in memory \n",
    "        agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n",
    "        # Start training after random sample generation\n",
    "        if(frame >= train_frame):\n",
    "            agent.train_policy_net(frame)\n",
    "            # Update the target network\n",
    "            if(frame % Update_target_network_frequency)== 0:\n",
    "                agent.update_target_net()\n",
    "        score += reward\n",
    "        history[:4, :, :] = history[1:, :, :]\n",
    "\n",
    "        if frame % 50000 == 0:\n",
    "            print('now time : ', datetime.now())\n",
    "            rewards.append(np.mean(evaluation_reward))\n",
    "            episodes.append(e)\n",
    "            pylab.plot(episodes, rewards, 'b')\n",
    "            pylab.savefig(\"./save_graph/breakout_dqn.png\")\n",
    "\n",
    "        if done:\n",
    "            evaluation_reward.append(score)\n",
    "            # every episode, plot the play time\n",
    "            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                  len(agent.memory), \"  epsilon:\", agent.epsilon, \"   steps:\", step,\n",
    "                  \"    evaluation reward:\", np.mean(evaluation_reward), \"frames:\", frame)\n",
    "\n",
    "            # if the mean of scores of last 10 episode is bigger than 400\n",
    "            # stop training\n",
    "            if np.mean(evaluation_reward) > 10:\n",
    "                torch.save(agent.model, \"./save_model/breakout_dqn\")\n",
    "                sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
